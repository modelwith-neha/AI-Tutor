{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a3a683-92d3-41ed-be78-98dd6b89131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch>=2.6.0 faiss-cpu gradio>=4.19.2 numpy bs4 sentence-transformers transformers>=4.39.0 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17db6a5d-eb80-4240-ae19-8569b6886385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.12/site-packages (6.31.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbbc2d23-fcd8-48cc-8bae-a0f592ecc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfd187e-717d-40c8-9b72-e0306a7aea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in ./.local/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.local/lib/python3.12/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.local/lib/python3.12/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6ae57a-953e-4138-b398-11a031037e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: blobfile in ./.local/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in ./.local/lib/python3.12/site-packages (from blobfile) (3.23.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in ./.local/lib/python3.12/site-packages (from blobfile) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.9 in ./.local/lib/python3.12/site-packages (from blobfile) (6.0.0)\n",
      "Requirement already satisfied: filelock>=3.0 in ./.local/lib/python3.12/site-packages (from blobfile) (3.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install blobfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167e23cc-ed2c-45f9-ac2f-42e191917f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-nd0snhdj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-nd0snhdj\n",
      "  Resolved https://github.com/huggingface/transformers to commit ccf2ca162e33f381e454cdb74bf4b41a51ab976d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.54.0.dev0) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.54.0.dev0) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.54.0.dev0) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (2025.6.15)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.54.0.dev0-py3-none-any.whl size=11784316 sha256=513e41b12dfcab2f2bf18a56a161b82bb415cf2ce6a01a2300139e1d4fd4ead4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-grr3lrs9/wheels/49/a7/50/c9fdabbf10e51bb1256adb0c1a587fedd7184f5bad28d47fe3\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.53.0\n",
      "    Uninstalling transformers-4.53.0:\n",
      "      Successfully uninstalled transformers-4.53.0\n",
      "Successfully installed transformers-4.54.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28972d6f-1d90-4514-aa43-8a8b24734119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Loading microsoft/Phi-3-mini-4k-instruct on GPU (or device_map=auto)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a271b50c4ef4456c82a4ab837d04e19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b818ab6ad0c245acb99a7da293ede786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409a3b225bbf475493105126b736baf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb6f581b8f24da2b29156587d93831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a77f933e3143f7b9f6f3b629691c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7942b25133489e9e39ece7789f02f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890956d8478b479da7faa3108cb716f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc4eb2b73984eaa99b365e1534b9539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1127c0438ef244e48c8eeb3617786d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bed95f04e94cabae4a3fdb6c97a0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecc5a19beb8434598ba2d51484606af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a240e724ca548f1a8f5099790bccd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655a0ca5e2464bb68546004776e7b165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611d7d2b75cd4cfab4e0a6bcd673541c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM loaded and ready!\n",
      "\n",
      "üöÄ Creating AI Tutor interface...\n",
      "üéâ AI Tutor ready!\n",
      "============================================================\n",
      "‚úÖ Complete Learning System Available:\n",
      "  üìö Learning Mode - Structured topic-based learning paths\n",
      "  üéì Tutor Mode - Socratic Q&A with guided discovery\n",
      "  üéÆ Game Mode - XP-based practice with flashcards, quizzes & coding\n",
      "  üåü Dynamic content generation with contextual quotes\n",
      "  üìñ Enhanced documentation (12+ sources)\n",
      "  üéØ From beginner Python to advanced GPU computing\n",
      "============================================================\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://2978ed2dadfa7ea500.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2978ed2dadfa7ea500.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üöÄ AI Tutor - Clean Working DataSci GPU Tutor (RAG + LLM + Game Mode)\n",
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "import torch\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import requests\n",
    "import random\n",
    "import difflib\n",
    "import re\n",
    "from types import SimpleNamespace\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, pipeline\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "# Includes: FAISS RAG system, fallback to Falcon-7B-Instruct, and full game mode\n",
    "\n",
    "\n",
    "# --- CONFIG ---\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "try:\n",
    "    embedder = SentenceTransformer(EMBED_MODEL, device='cuda')\n",
    "except (RuntimeError, OSError) as e:\n",
    "    print(f\"CUDA not available or out of memory ({e}), loading SentenceTransformer on CPU.\")\n",
    "    embedder = SentenceTransformer(EMBED_MODEL, device='cpu')\n",
    "#EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# LLM_MODEL = \"MiniMaxAI/SynLogic-7B\"\n",
    "# LLM_MODEL = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    " \n",
    "LLM_MODEL = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "#\"meta-llama/Meta-Llama-3-8B\"\n",
    "#\"allenai/digital-socrates-13b\"\n",
    "#\"/scratch/ntiwar12/huggingface/hub/models--WizardLM--WizardCoder-Python-34B-V1.0/snapshots/897fc6d9e12136c68c441b2350d015902c144b20/\"\n",
    "#\"allenai/digital-socrates-13b\"\n",
    "\n",
    "try:\n",
    "    print(f\"ü§ñ Loading {LLM_MODEL} on GPU (or device_map=auto)...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLM_MODEL,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    )\n",
    "except (RuntimeError, OSError) as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to load on GPU: {e}\\nLoading {LLM_MODEL} on CPU...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLM_MODEL,\n",
    "        trust_remote_code=True,\n",
    "        device_map={\"\": \"cpu\"},\n",
    "        torch_dtype=torch.float32\n",
    "    )\n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    return_full_text=False,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(\"‚úÖ LLM loaded and ready!\")\n",
    "#\"NousResearch/Hermes-2-Pro-Mistral-7B\"\n",
    "#https://huggingface.co/tecosys/Nutaan-RL1\n",
    "#https://huggingface.co/knowledgator/Qwen-encoder-0.5B\n",
    "#https://huggingface.co/knowledgator/Llama-encoder-1.0B\n",
    "CHUNK_FILE = \"chunks.pkl\"\n",
    "INDEX_FILE = \"faiss.index\" \n",
    "URLS_FILE = \"custom_urls.txt\"\n",
    "\n",
    "# Enhanced documentation system\n",
    "DOC_LINKS = {\n",
    "    'pandas': 'https://pandas.pydata.org/docs/',\n",
    "    'cudf': 'https://docs.rapids.ai/api/cudf/stable/',\n",
    "    'rapids': 'https://rapids.ai/',\n",
    "    'scikit-learn': 'https://scikit-learn.org/stable/',\n",
    "    'tensorflow': 'https://www.tensorflow.org/',\n",
    "    'pytorch': 'https://pytorch.org/docs/stable/',\n",
    "    'cuda_blog': 'https://developer.nvidia.com/blog/tag/cuda/',\n",
    "    'nvidia_tesla_whitepaper': 'https://www.nvidia.com/docs/io/116711/sc11-nv-tesla.pdf',\n",
    "    'gpu_compare': 'https://www.nvidia.com/en-us/geforce/graphics-cards/compare/',\n",
    "    'dsml_pdf': 'https://people.smp.uq.edu.au/DirkKroese/DSML/DSML.pdf',\n",
    "    'awesome_datascience': 'https://github.com/academic/awesome-datascience',\n",
    "    'gfg_ds_beginners': 'https://www.geeksforgeeks.org/data-science/data-science-for-beginners/'\n",
    "}\n",
    "\"\"\"\n",
    "# Initialize LLM pipeline (optional)\n",
    "llm_pipeline = None\n",
    "if TRANSFORMERS_AVAILABLE:\n",
    "    try:\n",
    "        print(\"ü§ñ Loading GPT-2 for dynamic content generation...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "        llm_pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            return_full_text=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        print(\"‚úÖ LLM loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LLM loading failed: {e}\")\n",
    "        llm_pipeline = None\n",
    "\"\"\"\n",
    "# === CORE FUNCTIONS ===\n",
    "\n",
    "def generate_contextual_quote(context=\"learning\", user_query=\"\"):\n",
    "    \"\"\"Generate contextual inspirational quotes\"\"\"\n",
    "    \n",
    "    # Try LLM generation first\n",
    "    if llm_pipeline:\n",
    "        try:\n",
    "            topic = extract_topic_from_query(user_query) if user_query else context\n",
    "            prompt = f\"Generate an inspiring quote about {topic} and learning:\"\n",
    "            result = llm_pipeline(prompt, max_new_tokens=50, temperature=0.8)\n",
    "            if result and len(result) > 0:\n",
    "                quote = result[0]['generated_text'].strip()\n",
    "                if len(quote) > 10:\n",
    "                    return f\"üß† '{quote}' - AI Generated\"\n",
    "        except Exception as e:\n",
    "            print(f\"Quote generation error: {e}\")\n",
    "    \n",
    "    # Enhanced fallback quotes\n",
    "    quotes = [\n",
    "        \"üí° 'Data is the new oil, but insights are the refined fuel.' - Anonymous\",\n",
    "        \"üöÄ 'The best way to get started is to quit talking and begin doing.' - Walt Disney\",\n",
    "        \"üß† 'Machine learning is the last invention that humanity will ever need to make.' - Nick Bostrom\",\n",
    "        \"‚ö° 'GPU acceleration: Think parallel, compute faster!' - AI Generated\",\n",
    "        \"üìä 'In data we trust, but insights we must discover!' - AI Generated\",\n",
    "        \"üî¨ 'Every algorithm learns from data, just like we learn from experience!' - AI Generated\",\n",
    "        \"üéØ 'The goal is to turn data into information, and information into insight.' - Carly Fiorina\",\n",
    "        \"üåü 'Artificial intelligence is the new electricity.' - Andrew Ng\",\n",
    "        \"‚öôÔ∏è 'The key to artificial intelligence has always been the representation.' - Jeff Hawkins\"\n",
    "    ]\n",
    "    return random.choice(quotes)\n",
    "\n",
    "def extract_topic_from_query(query):\n",
    "    \"\"\"Extract main topic from user query\"\"\"\n",
    "    if not query:\n",
    "        return \"learning\"\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    topic_keywords = {\n",
    "        'gpu computing': ['gpu', 'cuda', 'parallel', 'graphics'],\n",
    "        'data science': ['data', 'science', 'analytics', 'statistics'],\n",
    "        'machine learning': ['machine learning', 'ml', 'ai', 'artificial intelligence'],\n",
    "        'pandas': ['pandas', 'dataframe'],\n",
    "        'rapids': ['rapids', 'cudf', 'cuml'],\n",
    "        'programming': ['python', 'code', 'programming']\n",
    "    }\n",
    "    \n",
    "    for topic, keywords in topic_keywords.items():\n",
    "        if any(keyword in query_lower for keyword in keywords):\n",
    "            return topic\n",
    "    return 'learning'\n",
    "\n",
    "def smart_tutor_answer(query):\n",
    "    \"\"\"Generate Socratic tutor responses\"\"\"\n",
    "    if not query or query.strip() == \"\":\n",
    "        return \"ü§î Please ask me a question about data science, machine learning, or GPU computing!\", \"AI Tutor\"\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Topic-specific Socratic responses\n",
    "    if any(term in query_lower for term in ['rapids', 'cudf']):\n",
    "        return \"\"\"ü§î Let me guide you to discover RAPIDS:\n",
    "\n",
    "‚Ä¢ What challenges do data scientists face with large datasets on CPUs?\n",
    "‚Ä¢ How might GPU parallel processing help with data operations?\n",
    "‚Ä¢ What would happen if pandas operations could run on thousands of cores?\n",
    "\n",
    "üí° **Hint:** RAPIDS bridges GPU computing with familiar data science APIs like pandas.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    elif 'cuda' in query_lower:\n",
    "        return \"\"\"ü§î Let's explore CUDA together:\n",
    "\n",
    "‚Ä¢ What's the difference between CPU and GPU architecture?\n",
    "‚Ä¢ Why might graphics cards be useful for non-graphics tasks?\n",
    "‚Ä¢ How does parallel processing relate to data science?\n",
    "\n",
    "üí° **Hint:** CUDA stands for 'Compute Unified Device Architecture' - unified parallel computing.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    elif 'pandas' in query_lower:\n",
    "        return \"\"\"ü§î Let's think about pandas:\n",
    "\n",
    "‚Ä¢ What real-world structure does a DataFrame resemble?\n",
    "‚Ä¢ Why is structured data easier to work with than raw lists?\n",
    "‚Ä¢ How do you think pandas got its name?\n",
    "\n",
    "üí° **Hint:** Think about spreadsheets, databases, and 'panel data' in statistics.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    elif any(term in query_lower for term in ['machine learning', 'ml']):\n",
    "        return \"\"\"ü§î Let's approach machine learning conceptually:\n",
    "\n",
    "‚Ä¢ How is ML similar to how humans learn from experience?\n",
    "‚Ä¢ What's the difference between writing rules vs. learning patterns?\n",
    "‚Ä¢ Why might repetitive mathematical operations benefit from parallelization?\n",
    "\n",
    "üí° **Hint:** Consider the training process and computational intensity.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    # Generic response\n",
    "    return f\"\"\"ü§î Let's explore this together:\n",
    "\n",
    "‚Ä¢ What do you already know about {query}?\n",
    "‚Ä¢ How might this relate to data science or computing?\n",
    "‚Ä¢ What would you want to accomplish by understanding this better?\n",
    "\n",
    "üí° **Hint:** Break down the concept into smaller parts and think about how each works.\"\"\", \"Socratic Tutor\"\n",
    "\n",
    "def generate_flashcards(topic, n=3):\n",
    "    \"\"\"Generate educational flashcards\"\"\"\n",
    "    \n",
    "    # Try LLM generation\n",
    "    if llm_pipeline:\n",
    "        try:\n",
    "            prompt = f\"Create {n} educational flashcards about {topic}. Format: Q: question A: answer\"\n",
    "            result = llm_pipeline(prompt, max_new_tokens=200, temperature=0.7)\n",
    "            if result:\n",
    "                # Parse the result into flashcards (simplified)\n",
    "                text = result[0]['generated_text']\n",
    "                # Basic parsing - in practice you'd want more robust parsing\n",
    "                if 'Q:' in text and 'A:' in text:\n",
    "                    # Create a simple flashcard from the generated text\n",
    "                    return [{\"front\": f\"Generated question about {topic}\", \"back\": f\"Generated answer about {topic}\"}]\n",
    "        except Exception as e:\n",
    "            print(f\"Flashcard generation error: {e}\")\n",
    "    \n",
    "    # Fallback flashcards\n",
    "    flashcard_pools = {\n",
    "        \"cudf\": [\n",
    "            {\"front\": \"What is cuDF?\", \"back\": \"cuDF is a GPU DataFrame library with pandas-like API.\"},\n",
    "            {\"front\": \"How to convert pandas to cuDF?\", \"back\": \"Use cudf.from_pandas(df)\"},\n",
    "            {\"front\": \"Main advantage of cuDF?\", \"back\": \"GPU acceleration for large dataset processing\"}\n",
    "        ],\n",
    "        \"pandas\": [\n",
    "            {\"front\": \"What is a DataFrame?\", \"back\": \"A 2D labeled data structure with columns of different types.\"},\n",
    "            {\"front\": \"How to read CSV in pandas?\", \"back\": \"pd.read_csv('filename.csv')\"},\n",
    "            {\"front\": \"How to select a column?\", \"back\": \"df['column_name'] or df.column_name\"}\n",
    "        ],\n",
    "        \"rapids\": [\n",
    "            {\"front\": \"What is RAPIDS?\", \"back\": \"A suite of GPU-accelerated data science libraries.\"},\n",
    "            {\"front\": \"Main RAPIDS libraries?\", \"back\": \"cuDF, cuML, cuGraph for DataFrames, ML, and graphs.\"},\n",
    "            {\"front\": \"RAPIDS vs traditional tools?\", \"back\": \"Same APIs but with GPU acceleration for massive speedups.\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Get cards for topic, with fallback\n",
    "    cards = flashcard_pools.get(topic.lower(), [\n",
    "        {\"front\": f\"What is {topic}?\", \"back\": f\"{topic} is an important concept in data science.\"},\n",
    "        {\"front\": f\"Why learn {topic}?\", \"back\": f\"Understanding {topic} improves your data science skills.\"}\n",
    "    ])\n",
    "    \n",
    "    return cards[:n]\n",
    "\n",
    "def generate_quiz(topic, n=2):\n",
    "    \"\"\"Generate quiz questions\"\"\"\n",
    "    \n",
    "    # Quiz pools by topic\n",
    "    quiz_pools = {\n",
    "        \"pandas\": [\n",
    "            {\"question\": \"What is the main data structure in pandas?\", \"options\": [\"DataFrame\", \"Array\", \"List\", \"Dict\"], \"answer_idx\": 0},\n",
    "            {\"question\": \"How do you read a CSV file?\", \"options\": [\"pd.read_csv()\", \"pd.load()\", \"pd.import()\", \"pd.open()\"], \"answer_idx\": 0}\n",
    "        ],\n",
    "        \"cudf\": [\n",
    "            {\"question\": \"cuDF accelerates which library?\", \"options\": [\"NumPy\", \"Pandas\", \"SciPy\", \"Matplotlib\"], \"answer_idx\": 1},\n",
    "            {\"question\": \"cuDF runs on which hardware?\", \"options\": [\"CPU\", \"GPU\", \"TPU\", \"FPGA\"], \"answer_idx\": 1}\n",
    "        ],\n",
    "        \"rapids\": [\n",
    "            {\"question\": \"RAPIDS is developed by?\", \"options\": [\"Google\", \"Facebook\", \"NVIDIA\", \"Microsoft\"], \"answer_idx\": 2},\n",
    "            {\"question\": \"Main RAPIDS component for DataFrames?\", \"options\": [\"cuML\", \"cuDF\", \"cuGraph\", \"cuPy\"], \"answer_idx\": 1}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    questions = quiz_pools.get(topic.lower(), [\n",
    "        {\"question\": f\"What is {topic}?\", \"options\": [\"A tool\", \"A library\", \"A concept\", \"All of above\"], \"answer_idx\": 3},\n",
    "        {\"question\": f\"Why is {topic} important?\", \"options\": [\"Performance\", \"Efficiency\", \"Scale\", \"All of above\"], \"answer_idx\": 3}\n",
    "    ])\n",
    "    \n",
    "    return random.sample(questions, min(n, len(questions)))\n",
    "\n",
    "def generate_coding_puzzle(difficulty=\"Beginner\"):\n",
    "    \"\"\"Generate coding puzzles for pandas to cuDF conversion\"\"\"\n",
    "    \n",
    "    puzzles = {\n",
    "        \"Beginner\": {\n",
    "            \"description\": \"Convert basic DataFrame creation from pandas to cuDF\",\n",
    "            \"cpu_code\": \"import pandas as pd\\ndf = pd.DataFrame({'a': [1, 2, 3]})\\nprint(df)\",\n",
    "            \"gpu_code\": \"import cudf\\ndf = cudf.DataFrame({'a': [1, 2, 3]})\\nprint(df)\",\n",
    "            \"cpu_time\": 1.2,\n",
    "            \"gpu_time\": 0.2\n",
    "        },\n",
    "        \"Intermediate\": {\n",
    "            \"description\": \"Convert groupby operation from pandas to cuDF\",\n",
    "            \"cpu_code\": \"import pandas as pd\\ndf = pd.DataFrame({'group': ['A', 'B', 'A'], 'value': [1, 2, 3]})\\nresult = df.groupby('group').sum()\",\n",
    "            \"gpu_code\": \"import cudf\\ndf = cudf.DataFrame({'group': ['A', 'B', 'A'], 'value': [1, 2, 3]})\\nresult = df.groupby('group').sum()\",\n",
    "            \"cpu_time\": 3.2,\n",
    "            \"gpu_time\": 0.5\n",
    "        },\n",
    "        \"Advanced\": {\n",
    "            \"description\": \"Convert complex aggregation from pandas to cuDF\",\n",
    "            \"cpu_code\": \"import pandas as pd\\ndf = pd.DataFrame({'cat': ['A', 'B'], 'val1': [1, 2], 'val2': [3, 4]})\\nresult = df.groupby('cat').agg({'val1': 'sum', 'val2': 'mean'})\",\n",
    "            \"gpu_code\": \"import cudf\\ndf = cudf.DataFrame({'cat': ['A', 'B'], 'val1': [1, 2], 'val2': [3, 4]})\\nresult = df.groupby('cat').agg({'val1': 'sum', 'val2': 'mean'})\",\n",
    "            \"cpu_time\": 4.2,\n",
    "            \"gpu_time\": 0.6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return puzzles.get(difficulty, puzzles[\"Beginner\"])\n",
    "\n",
    "def search_knowledge_base(query):\n",
    "    \"\"\"Enhanced RAG search with documentation\"\"\"\n",
    "    if not query:\n",
    "        return \"Please provide a specific question.\"\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Find relevant documentation\n",
    "    relevant_docs = []\n",
    "    for doc_name, doc_url in DOC_LINKS.items():\n",
    "        if any(term in doc_name for term in query_lower.split()):\n",
    "            relevant_docs.append(f\"‚Ä¢ **{doc_name}**: {doc_url}\")\n",
    "    \n",
    "    if not relevant_docs:\n",
    "        # Default docs for common topics\n",
    "        if 'pandas' in query_lower:\n",
    "            relevant_docs = [f\"‚Ä¢ **pandas**: {DOC_LINKS['pandas']}\"]\n",
    "        elif 'cudf' in query_lower:\n",
    "            relevant_docs = [f\"‚Ä¢ **cudf**: {DOC_LINKS['cudf']}\"]\n",
    "        else:\n",
    "            relevant_docs = [f\"‚Ä¢ **rapids**: {DOC_LINKS['rapids']}\"]\n",
    "    \n",
    "    context = f\"üìö **Relevant Documentation:**\\n\" + \"\\n\".join(relevant_docs[:3])\n",
    "    \n",
    "    # Add topic-specific information\n",
    "    if 'cudf' in query_lower:\n",
    "        context += \"\\n\\nüí° **Key Info:** cuDF provides pandas-like API with GPU acceleration\"\n",
    "    elif 'rapids' in query_lower:\n",
    "        context += \"\\n\\nüí° **Key Info:** RAPIDS ecosystem includes cuDF, cuML, cuGraph\"\n",
    "    elif 'pandas' in query_lower:\n",
    "        context += \"\\n\\nüí° **Key Info:** pandas provides DataFrames for data analysis\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# === GRADIO INTERFACE ===\n",
    "\n",
    "def create_ai_tutor():\n",
    "    \"\"\"Create the AI Tutor Gradio interface\"\"\"\n",
    "    \n",
    "    with gr.Blocks(theme=gr.themes.Soft(), title=\"üß† AI Tutor\") as app:\n",
    "        \n",
    "        # Header\n",
    "        gr.Markdown(\"\"\"\n",
    "        <div style='text-align:center; background:linear-gradient(90deg,#fff1c1,#c1e7ff,#e1ffc1); border-radius:15px; padding:15px; margin-bottom:20px; color:#000;'>\n",
    "          <h1 style='color:#000; text-shadow: 1px 1px 2px rgba(0,0,0,0.1);'>üß† AI Tutor - Complete Learning System</h1>\n",
    "          <h3 style='color:#000; font-weight:700; text-shadow: 1px 1px 2px rgba(0,0,0,0.1);'>üìö Learning Mode ‚Ä¢ üéì Socratic Tutoring ‚Ä¢ üéÆ Gamified Practice</h3>\n",
    "          <p style='color:#000; font-weight:600; text-shadow: 1px 1px 2px rgba(0,0,0,0.1);'><b>üìö Structured Learning Paths ‚Ä¢ ü§î Guided Discovery ‚Ä¢ üéØ Interactive Practice</b></p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Add custom CSS for better styling\n",
    "        app.css = \"\"\"\n",
    "        .learning-topic-btn {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;\n",
    "            color: white !important;\n",
    "            border: none !important;\n",
    "            border-radius: 12px !important;\n",
    "            padding: 15px !important;\n",
    "            margin: 8px !important;\n",
    "            font-weight: 600 !important;\n",
    "            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4) !important;\n",
    "            transition: all 0.3s ease !important;\n",
    "            min-height: 80px !important;\n",
    "            font-size: 14px !important;\n",
    "        }\n",
    "        .learning-topic-btn:hover {\n",
    "            transform: translateY(-2px) !important;\n",
    "            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6) !important;\n",
    "        }\n",
    "        \n",
    "        /* Make tab headers more prominent */\n",
    "        .gradio-tab-nav {\n",
    "            background: linear-gradient(90deg, #f8fafc, #e2e8f0) !important;\n",
    "            border-radius: 8px !important;\n",
    "            padding: 8px !important;\n",
    "            margin-bottom: 20px !important;\n",
    "            box-shadow: 0 2px 8px rgba(0,0,0,0.1) !important;\n",
    "        }\n",
    "        \n",
    "        .gradio-tab-nav .tab-nav {\n",
    "            background: linear-gradient(135deg, #4f46e5, #7c3aed) !important;\n",
    "            color: white !important;\n",
    "            font-weight: 700 !important;\n",
    "            font-size: 16px !important;\n",
    "            border-radius: 6px !important;\n",
    "            margin: 4px !important;\n",
    "            padding: 12px 20px !important;\n",
    "            box-shadow: 0 2px 4px rgba(79, 70, 229, 0.3) !important;\n",
    "            border: none !important;\n",
    "        }\n",
    "        \n",
    "        .gradio-tab-nav .tab-nav:hover {\n",
    "            background: linear-gradient(135deg, #6366f1, #8b5cf6) !important;\n",
    "            transform: translateY(-1px) !important;\n",
    "            box-shadow: 0 4px 8px rgba(79, 70, 229, 0.4) !important;\n",
    "        }\n",
    "        \n",
    "        .gradio-tab-nav .tab-nav.selected {\n",
    "            background: linear-gradient(135deg, #059669, #0d9488) !important;\n",
    "            box-shadow: 0 4px 12px rgba(5, 150, 105, 0.4) !important;\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        with gr.Tabs():\n",
    "            \n",
    "            # === LEARNING MODE ===\n",
    "            with gr.Tab(\"üìö Learning Mode\"):\n",
    "                gr.Markdown(\"### üéØ **Choose a Learning Path - From Beginner to Advanced**\")\n",
    "                gr.Markdown(\"*Select any topic below to get a structured learning journey with resources and related topics*\")\n",
    "                \n",
    "                # Learning topics with structured paths\n",
    "                LEARNING_TOPICS = {\n",
    "                    \"Python for Data Science\": {\n",
    "                        \"description\": \"Master Python fundamentals and data science libraries\",\n",
    "                        \"level\": \"üü¢ Beginner to Intermediate\",\n",
    "                        \"duration\": \"4-6 weeks\",\n",
    "                        \"prerequisites\": \"Basic programming knowledge\",\n",
    "                        \"content\": \"\"\"\n",
    "**üìñ Learning Path:**\n",
    "1. **Python Basics** - Variables, data types, control structures\n",
    "2. **NumPy** - Numerical computing and arrays\n",
    "3. **Pandas** - Data manipulation and analysis\n",
    "4. **Matplotlib/Seaborn** - Data visualization\n",
    "5. **Jupyter Notebooks** - Interactive development\n",
    "\n",
    "**üîó Key Resources:**\n",
    "‚Ä¢ [Python.org Tutorial](https://docs.python.org/3/tutorial/)\n",
    "‚Ä¢ [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "‚Ä¢ [NumPy User Guide](https://numpy.org/doc/stable/user/)\n",
    "\n",
    "**üöÄ Next Steps:** Machine Learning Fundamentals, Data Visualization\n",
    "\"\"\",\n",
    "                        \"related\": [\"Machine Learning Fundamentals\", \"Data Visualization\", \"Pandas Deep Dive\"]\n",
    "                    },\n",
    "                    \"Pandas Deep Dive\": {\n",
    "                        \"description\": \"Master DataFrame operations, data cleaning, and advanced pandas techniques\",\n",
    "                        \"level\": \"üü° Intermediate\",\n",
    "                        \"duration\": \"3-4 weeks\", \n",
    "                        \"prerequisites\": \"Python basics, basic pandas knowledge\",\n",
    "                        \"content\": \"\"\"\n",
    "**üìñ Learning Path:**\n",
    "1. **DataFrame Mastery** - Creation, indexing, selection\n",
    "2. **Data Cleaning** - Missing values, duplicates, data types\n",
    "3. **GroupBy Operations** - Aggregation and transformation\n",
    "4. **Merging & Joining** - Combining datasets\n",
    "5. **Performance Optimization** - Efficient pandas operations\n",
    "\n",
    "**üîó Key Resources:**\n",
    "‚Ä¢ [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "‚Ä¢ [Pandas Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html)\n",
    "‚Ä¢ [10 Minutes to Pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "\n",
    "**üöÄ Next Steps:** GPU Acceleration with cuDF, Time Series Analysis\n",
    "\"\"\",\n",
    "                        \"related\": [\"GPU Acceleration with cuDF\", \"Data Visualization\", \"Time Series Analysis\"]\n",
    "                    },\n",
    "                    \"GPU Acceleration with cuDF\": {\n",
    "                        \"description\": \"Learn GPU-accelerated data processing with RAPIDS cuDF\",\n",
    "                        \"level\": \"üî¥ Advanced\",\n",
    "                        \"duration\": \"2-3 weeks\",\n",
    "                        \"prerequisites\": \"Strong pandas knowledge, basic GPU concepts\",\n",
    "                        \"content\": \"\"\"\n",
    "**üìñ Learning Path:**\n",
    "1. **GPU Computing Basics** - Understanding parallel processing\n",
    "2. **cuDF Introduction** - GPU DataFrames and basic operations\n",
    "3. **Migration from Pandas** - Converting existing code\n",
    "4. **Performance Optimization** - Memory management and best practices\n",
    "5. **Advanced Operations** - Complex aggregations and joins\n",
    "\n",
    "**üîó Key Resources:**\n",
    "‚Ä¢ [RAPIDS cuDF Documentation](https://docs.rapids.ai/api/cudf/stable/)\n",
    "‚Ä¢ [cuDF User Guide](https://docs.rapids.ai/api/cudf/stable/user_guide/)\n",
    "‚Ä¢ [RAPIDS Getting Started](https://rapids.ai/start.html)\n",
    "\n",
    "**üöÄ Next Steps:** RAPIDS Ecosystem, Machine Learning with cuML\n",
    "\"\"\",\n",
    "                        \"related\": [\"RAPIDS Ecosystem\", \"CUDA Programming\", \"High-Performance Computing\"]\n",
    "                    },\n",
    "                    \"Machine Learning Fundamentals\": {\n",
    "                        \"description\": \"Core ML concepts, algorithms, and scikit-learn implementation\",\n",
    "                        \"level\": \"üü° Intermediate\",\n",
    "                        \"duration\": \"6-8 weeks\",\n",
    "                        \"prerequisites\": \"Python, pandas, basic statistics\",\n",
    "                        \"content\": \"\"\"\n",
    "**üìñ Learning Path:**\n",
    "1. **ML Concepts** - Supervised, unsupervised, reinforcement learning\n",
    "2. **Data Preprocessing** - Feature scaling, encoding, train-test splits\n",
    "3. **Regression Algorithms** - Linear, polynomial, regularization\n",
    "4. **Classification** - Logistic regression, decision trees, SVM\n",
    "5. **Model Evaluation** - Cross-validation, metrics, hyperparameter tuning\n",
    "\n",
    "**üîó Key Resources:**\n",
    "‚Ä¢ [Scikit-learn Documentation](https://scikit-learn.org/stable/)\n",
    "‚Ä¢ [Machine Learning Course by Andrew Ng](https://www.coursera.org/learn/machine-learning)\n",
    "‚Ä¢ [Hands-On Machine Learning](https://github.com/ageron/handson-ml2)\n",
    "\n",
    "**üöÄ Next Steps:** Deep Learning, GPU-Accelerated ML with cuML\n",
    "\"\"\",\n",
    "                        \"related\": [\"Deep Learning Fundamentals\", \"GPU-Accelerated ML\", \"Data Science Projects\"]\n",
    "                    },\n",
    "                    \"RAPIDS Ecosystem\": {\n",
    "                        \"description\": \"Complete RAPIDS suite: cuDF, cuML, cuGraph for end-to-end GPU data science\",\n",
    "                        \"level\": \"üî¥ Advanced\",\n",
    "                        \"duration\": \"4-5 weeks\",\n",
    "                        \"prerequisites\": \"GPU computing basics, pandas, scikit-learn\",\n",
    "                        \"content\": \"\"\"\n",
    "**üìñ Learning Path:**\n",
    "1. **RAPIDS Overview** - cuDF, cuML, cuGraph, cuPy integration\n",
    "2. **cuDF Mastery** - Advanced DataFrame operations on GPU\n",
    "3. **cuML for ML** - GPU-accelerated machine learning algorithms\n",
    "4. **cuGraph** - Graph analytics and network analysis\n",
    "5. **End-to-End Workflows** - Complete GPU data science pipelines\n",
    "\n",
    "**üîó Key Resources:**\n",
    "‚Ä¢ [RAPIDS.ai Main Site](https://rapids.ai/)\n",
    "‚Ä¢ [RAPIDS Documentation](https://docs.rapids.ai/)\n",
    "‚Ä¢ [RAPIDS Community](https://github.com/rapidsai)\n",
    "\n",
    "**üöÄ Next Steps:** Production Deployment, Multi-GPU Computing\n",
    "\"\"\",\n",
    "                        \"related\": [\"Multi-GPU Computing\", \"Production ML Systems\", \"CUDA Programming\"]\n",
    "                    },\n",
    "                    \"Data Visualization\": {\n",
    "                        \"description\": \"Create compelling data visualizations with matplotlib, seaborn, and plotly\",\n",
    "                        \"level\": \"üü¢ Beginner to Intermediate\",\n",
    "                        \"duration\": \"3-4 weeks\",\n",
    "                        \"prerequisites\": \"Python basics, pandas fundamentals\",\n",
    "                        \"content\": \"\"\"\n",
    "**üìñ Learning Path:**\n",
    "1. **Matplotlib Basics** - Plots, figures, axes, customization\n",
    "2. **Seaborn for Statistics** - Statistical plots and themes\n",
    "3. **Interactive Plotly** - Dynamic and web-ready visualizations\n",
    "4. **Advanced Techniques** - Subplots, animations, custom plots\n",
    "5. **Dashboard Creation** - Streamlit, Dash for interactive apps\n",
    "\n",
    "**üîó Key Resources:**\n",
    "‚Ä¢ [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)\n",
    "‚Ä¢ [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html)\n",
    "‚Ä¢ [Plotly Python Guide](https://plotly.com/python/)\n",
    "\n",
    "**üöÄ Next Steps:** Interactive Dashboards, Business Intelligence\n",
    "\"\"\",\n",
    "                        \"related\": [\"Interactive Dashboards\", \"Business Intelligence\", \"Web Development for Data Science\"]\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                # Topic selection buttons\n",
    "                with gr.Row():\n",
    "                    topic_buttons = []\n",
    "                    for i, (topic_name, topic_info) in enumerate(LEARNING_TOPICS.items()):\n",
    "                        if i % 2 == 0 and i > 0:\n",
    "                            # Start new row every 2 buttons\n",
    "                            pass\n",
    "                        \n",
    "                        color_map = {\n",
    "                            \"üü¢\": \"#dcfce7\",  # Green for beginner\n",
    "                            \"üü°\": \"#fef3c7\",  # Yellow for intermediate  \n",
    "                            \"üî¥\": \"#fee2e2\"   # Red for advanced\n",
    "                        }\n",
    "                        level_color = color_map.get(topic_info[\"level\"][0], \"#f3f4f6\")\n",
    "                        \n",
    "                        btn = gr.Button(\n",
    "                            f\"{topic_name}\\n{topic_info['level']}\",\n",
    "                            elem_classes=\"learning-topic-btn\",\n",
    "                            size=\"lg\"\n",
    "                        )\n",
    "                        topic_buttons.append((btn, topic_name))\n",
    "                \n",
    "                # Learning content display\n",
    "                learning_content = gr.Markdown()\n",
    "                related_topics = gr.Markdown()\n",
    "                \n",
    "                def show_learning_content(topic_name):\n",
    "                    if topic_name not in LEARNING_TOPICS:\n",
    "                        return \"Topic not found!\", \"\"\n",
    "                    \n",
    "                    topic = LEARNING_TOPICS[topic_name]\n",
    "                    \n",
    "                    content = f\"\"\"\n",
    "# üìö {topic_name}\n",
    "\n",
    "**üìã Description:** {topic['description']}\n",
    "\n",
    "**üìä Level:** {topic['level']} | **‚è±Ô∏è Duration:** {topic['duration']} | **üìö Prerequisites:** {topic['prerequisites']}\n",
    "\n",
    "---\n",
    "\n",
    "{topic['content']}\n",
    "\n",
    "---\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    related = f\"\"\"\n",
    "### üîó **Related Learning Paths:**\n",
    "{' ‚Ä¢ '.join([f\"**{rel}**\" for rel in topic['related']])}\n",
    "\n",
    "üí° *Click any topic above to explore these related learning paths!*\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    return content, related\n",
    "                \n",
    "                # Connect buttons to content display\n",
    "                for btn, topic_name in topic_buttons:\n",
    "                    btn.click(\n",
    "                        lambda tn=topic_name: show_learning_content(tn),\n",
    "                        outputs=[learning_content, related_topics]\n",
    "                    )\n",
    "                \n",
    "                # Search functionality\n",
    "                with gr.Row():\n",
    "                    search_topic = gr.Textbox(\n",
    "                        label=\"üîç Search for specific topics\",\n",
    "                        placeholder=\"e.g., neural networks, time series, NLP, computer vision...\"\n",
    "                    )\n",
    "                    search_btn = gr.Button(\"Search Learning Resources\")\n",
    "                \n",
    "                search_results = gr.Markdown()\n",
    "                \n",
    "                def search_learning_resources(query):\n",
    "                    if not query:\n",
    "                        return \"Please enter a search term!\"\n",
    "                    \n",
    "                    # Simulate search results with relevant resources\n",
    "                    query_lower = query.lower()\n",
    "                    \n",
    "                    results = []\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['neural', 'deep', 'cnn', 'rnn', 'transformer']):\n",
    "                        results.append(\"\"\"\n",
    "**üß† Deep Learning Resources:**\n",
    "‚Ä¢ [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)\n",
    "‚Ä¢ [PyTorch Tutorials](https://pytorch.org/tutorials/)\n",
    "‚Ä¢ [TensorFlow Guide](https://www.tensorflow.org/guide)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['nlp', 'text', 'language', 'sentiment']):\n",
    "                        results.append(\"\"\"\n",
    "**üìù Natural Language Processing:**\n",
    "‚Ä¢ [NLTK Documentation](https://www.nltk.org/)\n",
    "‚Ä¢ [spaCy Course](https://course.spacy.io/)\n",
    "‚Ä¢ [Hugging Face Transformers](https://huggingface.co/transformers/)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['time series', 'forecasting', 'temporal']):\n",
    "                        results.append(\"\"\"\n",
    "**üìà Time Series Analysis:**\n",
    "‚Ä¢ [Time Series Analysis Guide](https://www.statsmodels.org/stable/tsa.html)\n",
    "‚Ä¢ [Prophet Forecasting](https://facebook.github.io/prophet/)\n",
    "‚Ä¢ [Time Series with Python](https://github.com/marcopeix/TimeSeriesForecastingInPython)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['computer vision', 'image', 'cv', 'opencv']):\n",
    "                        results.append(\"\"\"\n",
    "**üëÅÔ∏è Computer Vision:**\n",
    "‚Ä¢ [OpenCV Tutorials](https://docs.opencv.org/master/d9/df8/tutorial_root.html)\n",
    "‚Ä¢ [Computer Vision Course](https://www.coursera.org/learn/convolutional-neural-networks)\n",
    "‚Ä¢ [Fast.ai Practical Deep Learning](https://course.fast.ai/)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if not results:\n",
    "                        results.append(f\"\"\"\n",
    "**üîç Search Results for \"{query}\":**\n",
    "\n",
    "*No specific resources found. Try these general resources:*\n",
    "‚Ä¢ [Kaggle Learn](https://www.kaggle.com/learn) - Free micro-courses\n",
    "‚Ä¢ [Coursera Data Science](https://www.coursera.org/browse/data-science)\n",
    "‚Ä¢ [edX MIT Data Science](https://www.edx.org/course/introduction-to-computational-thinking-and-data-science)\n",
    "\n",
    "*Or refine your search with terms like: machine learning, deep learning, NLP, computer vision, time series*\n",
    "\"\"\")\n",
    "                    \n",
    "                    return \"\\n\".join(results)\n",
    "                \n",
    "                search_btn.click(search_learning_resources, inputs=search_topic, outputs=search_results)\n",
    "\n",
    "            # === TUTOR MODE ===\n",
    "            with gr.Tab(\"üéì Tutor Mode\"):\n",
    "                gr.Markdown(\"### ü§î **Socratic Learning - Ask Questions, Get Guided Answers**\")\n",
    "                gr.Markdown(\"*I won't give you direct answers, but I'll guide you to discover the knowledge yourself!*\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        tutor_query = gr.Textbox(\n",
    "                            label=\"Ask about Data Science, GPU Computing, or type 'docs' for documentation\",\n",
    "                            placeholder=\"e.g., What is RAPIDS? How does cuDF work? Why use GPU for data science?\",\n",
    "                            lines=2\n",
    "                        )\n",
    "                        tutor_btn = gr.Button(\"üöÄ Get Socratic Guidance\", variant=\"primary\")\n",
    "                    \n",
    "                    with gr.Column(scale=1):\n",
    "                        quote_display = gr.Markdown(\"üí° *Ready to discover knowledge!*\")\n",
    "                \n",
    "                tutor_answer = gr.Markdown(label=\"ü§î Socratic Guidance\")\n",
    "                tutor_source = gr.Markdown(label=\"üìö Source\")\n",
    "                \n",
    "                # Quick question suggestions\n",
    "                with gr.Row():\n",
    "                    quick_questions = [\n",
    "                        \"Why use GPUs for data science?\",\n",
    "                        \"How does parallel processing work?\", \n",
    "                        \"What makes cuDF faster than pandas?\",\n",
    "                        \"When should I use machine learning?\"\n",
    "                    ]\n",
    "                    for i, question in enumerate(quick_questions):\n",
    "                        if i % 2 == 0:\n",
    "                            with gr.Column():\n",
    "                                pass\n",
    "                        quick_btn = gr.Button(f\"üí≠ {question}\", size=\"sm\")\n",
    "                        quick_btn.click(lambda q=question: q, outputs=tutor_query)\n",
    "                \n",
    "                def handle_tutor_query(query):\n",
    "                    if not query:\n",
    "                        return \"Please ask a question!\", \"AI Tutor\", \"üí° *Ready to help!*\"\n",
    "                    \n",
    "                    # Handle docs command\n",
    "                    if query.lower().strip() in ['docs', 'documentation', 'help']:\n",
    "                        docs_info = \"\"\"üìö **Available Documentation:**\n",
    "‚Ä¢ **Core Libraries:** pandas, cuDF, RAPIDS, scikit-learn\n",
    "‚Ä¢ **GPU Computing:** CUDA, NVIDIA resources  \n",
    "‚Ä¢ **Data Science:** Comprehensive guides and tutorials\n",
    "*Ask any topic-specific question to get relevant documentation!*\"\"\"\n",
    "                        return docs_info, \"Documentation System\", \"üìñ *Knowledge at your fingertips!*\"\n",
    "                    \n",
    "                    # Generate contextual quote\n",
    "                    quote = generate_contextual_quote(extract_topic_from_query(query), query)\n",
    "                    \n",
    "                    # Get tutor response\n",
    "                    answer, source = smart_tutor_answer(query)\n",
    "                    \n",
    "                    return answer, f\"**Source:** {source}\", f\"üåü {quote}\"\n",
    "                \n",
    "                tutor_btn.click(handle_tutor_query, inputs=tutor_query, outputs=[tutor_answer, tutor_source, quote_display])\n",
    "                tutor_query.submit(handle_tutor_query, inputs=tutor_query, outputs=[tutor_answer, tutor_source, quote_display])\n",
    "            \n",
    "            # === GAME MODE ===\n",
    "            with gr.Tab(\"üéÆ Game Mode\"):\n",
    "                user_state = SimpleNamespace(points=0)\n",
    "                \n",
    "                def update_progress():\n",
    "                    level = user_state.points // 20 + 1\n",
    "                    bar_width = min((user_state.points % 20) * 5, 100)\n",
    "                    return f\"\"\"<h3>üèÜ Level {level} | üî• {user_state.points} XP</h3>\n",
    "                    <div style='background: #e5e7eb; height: 20px; border-radius: 10px;'>\n",
    "                        <div style='background: linear-gradient(90deg, #4ade80, #22c55e); height: 20px; width: {bar_width}%; border-radius: 10px;'></div>\n",
    "                    </div>\"\"\"\n",
    "                \n",
    "                progress = gr.HTML(update_progress())\n",
    "                \n",
    "                with gr.Tabs():\n",
    "                    \n",
    "                    # === FLASHCARDS ===\n",
    "                    with gr.Tab(\"üé¥ Flashcards\"):\n",
    "                        flashcard_topic = gr.Textbox(label=\"Topic\", placeholder=\"e.g., cuDF, pandas, RAPIDS\")\n",
    "                        gen_flashcards_btn = gr.Button(\"‚ú® Generate Flashcards\")\n",
    "                        \n",
    "                        card_display = gr.Markdown()\n",
    "                        card_back = gr.Markdown(visible=False)\n",
    "                        flip_btn = gr.Button(\"üîÑ Flip\", visible=False)\n",
    "                        next_btn = gr.Button(\"‚û°Ô∏è Next\", visible=False)\n",
    "                        \n",
    "                        flashcards_state = gr.State([])\n",
    "                        card_idx = gr.State(0)\n",
    "                        show_back = gr.State(False)\n",
    "                        \n",
    "                        def generate_cards(topic):\n",
    "                            if not topic:\n",
    "                                return \"Enter a topic first!\", \"\", gr.update(visible=False), gr.update(visible=False), [], 0, False\n",
    "                            \n",
    "                            cards = generate_flashcards(topic, 5)\n",
    "                            first_card = cards[0]\n",
    "                            return (\n",
    "                                f\"**Card 1/{len(cards)}**\\n\\nüé¥ **Q:** {first_card['front']}\",\n",
    "                                \"\",\n",
    "                                gr.update(visible=True),\n",
    "                                gr.update(visible=True),\n",
    "                                cards,\n",
    "                                0,\n",
    "                                False\n",
    "                            )\n",
    "                        \n",
    "                        def flip_card(idx, show, cards):\n",
    "                            if not cards:\n",
    "                                return \"\", False\n",
    "                            card = cards[idx]\n",
    "                            if not show:\n",
    "                                return f\"**A:** {card['back']}\", True\n",
    "                            else:\n",
    "                                return \"\", False\n",
    "                        \n",
    "                        def next_card(idx, cards):\n",
    "                            if not cards:\n",
    "                                return \"\", 0, False\n",
    "                            new_idx = (idx + 1) % len(cards)\n",
    "                            card = cards[new_idx]\n",
    "                            user_state.points += 1\n",
    "                            return f\"**Card {new_idx+1}/{len(cards)}**\\n\\nüé¥ **Q:** {card['front']}\", new_idx, False\n",
    "                        \n",
    "                        gen_flashcards_btn.click(generate_cards, inputs=flashcard_topic, \n",
    "                                               outputs=[card_display, card_back, flip_btn, next_btn, flashcards_state, card_idx, show_back])\n",
    "                        flip_btn.click(flip_card, inputs=[card_idx, show_back, flashcards_state], \n",
    "                                     outputs=[card_back, show_back])\n",
    "                        next_btn.click(next_card, inputs=[card_idx, flashcards_state], \n",
    "                                     outputs=[card_display, card_idx, show_back])\n",
    "                    \n",
    "                    # === QUIZ ===\n",
    "                    with gr.Tab(\"‚ùì Quiz\"):\n",
    "                        quiz_topic = gr.Textbox(label=\"Quiz Topic\", placeholder=\"e.g., pandas, cuDF, RAPIDS\")\n",
    "                        gen_quiz_btn = gr.Button(\"üß† Generate Quiz\")\n",
    "                        \n",
    "                        quiz_q1 = gr.Markdown()\n",
    "                        quiz_r1 = gr.Radio(choices=[], label=\"Answer:\", visible=False)\n",
    "                        quiz_q2 = gr.Markdown()\n",
    "                        quiz_r2 = gr.Radio(choices=[], label=\"Answer:\", visible=False)\n",
    "                        \n",
    "                        submit_btn = gr.Button(\"Submit Quiz\", visible=False)\n",
    "                        quiz_result = gr.Markdown()\n",
    "                        quiz_state = gr.State([])\n",
    "                        \n",
    "                        def generate_quiz_questions(topic):\n",
    "                            if not topic:\n",
    "                                return \"Enter a topic!\", gr.update(visible=False), \"\", gr.update(visible=False), gr.update(visible=False), []\n",
    "                            \n",
    "                            questions = generate_quiz(topic, 2)\n",
    "                            return (\n",
    "                                f\"**Q1:** {questions[0]['question']}\",\n",
    "                                gr.update(choices=questions[0]['options'], visible=True, value=None),\n",
    "                                f\"**Q2:** {questions[1]['question']}\",\n",
    "                                gr.update(choices=questions[1]['options'], visible=True, value=None),\n",
    "                                gr.update(visible=True),\n",
    "                                questions\n",
    "                            )\n",
    "                        \n",
    "                        def evaluate_quiz(ans1, ans2, questions):\n",
    "                            if not questions:\n",
    "                                return \"Quiz not loaded!\"\n",
    "                            \n",
    "                            correct = 0\n",
    "                            result_parts = []\n",
    "                            \n",
    "                            # Check Q1\n",
    "                            correct_ans1 = questions[0]['options'][questions[0]['answer_idx']]\n",
    "                            if ans1 and ans1 == correct_ans1:\n",
    "                                correct += 1\n",
    "                                result_parts.append(f\"‚úÖ **Q1:** Correct! ({ans1})\")\n",
    "                            else:\n",
    "                                result_parts.append(f\"‚ùå **Q1:** Wrong. You answered: {ans1 or 'None'}\")\n",
    "                                result_parts.append(f\"    üí° **Correct answer:** {correct_ans1}\")\n",
    "                            \n",
    "                            # Check Q2  \n",
    "                            correct_ans2 = questions[1]['options'][questions[1]['answer_idx']]\n",
    "                            if ans2 and ans2 == correct_ans2:\n",
    "                                correct += 1\n",
    "                                result_parts.append(f\"‚úÖ **Q2:** Correct! ({ans2})\")\n",
    "                            else:\n",
    "                                result_parts.append(f\"‚ùå **Q2:** Wrong. You answered: {ans2 or 'None'}\")\n",
    "                                result_parts.append(f\"    üí° **Correct answer:** {correct_ans2}\")\n",
    "                            \n",
    "                            user_state.points += correct * 5\n",
    "                            \n",
    "                            # Overall result\n",
    "                            score_emoji = \"üéâ\" if correct == 2 else \"üëç\" if correct == 1 else \"üìö\"\n",
    "                            result_parts.insert(0, f\"{score_emoji} **Final Score: {correct}/2 correct! +{correct*5} XP**\")\n",
    "                            result_parts.append(f\"\\nüèÜ **Total XP:** {user_state.points}\")\n",
    "                            \n",
    "                            return \"\\n\".join(result_parts)\n",
    "                        \n",
    "                        gen_quiz_btn.click(generate_quiz_questions, inputs=quiz_topic,\n",
    "                                         outputs=[quiz_q1, quiz_r1, quiz_q2, quiz_r2, submit_btn, quiz_state])\n",
    "                        submit_btn.click(evaluate_quiz, inputs=[quiz_r1, quiz_r2, quiz_state], outputs=quiz_result)\n",
    "                    \n",
    "                    # === CODING PUZZLES ===\n",
    "                    with gr.Tab(\"üíª Coding\"):\n",
    "                        difficulty = gr.Radio(choices=[\"Beginner\", \"Intermediate\", \"Advanced\"], \n",
    "                                            value=\"Beginner\", label=\"Difficulty\")\n",
    "                        gen_puzzle_btn = gr.Button(\"üéØ Generate Puzzle\")\n",
    "                        \n",
    "                        puzzle_desc = gr.Markdown()\n",
    "                        cpu_code = gr.Code(label=\"CPU Code (pandas)\", interactive=False)\n",
    "                        user_code = gr.Code(label=\"Your GPU Code (cuDF)\", language=\"python\")\n",
    "                        \n",
    "                        check_btn = gr.Button(\"‚úÖ Check Solution\")\n",
    "                        benchmark_btn = gr.Button(\"‚ö° Benchmark\")\n",
    "                        \n",
    "                        puzzle_feedback = gr.Markdown()\n",
    "                        puzzle_state = gr.State({})\n",
    "                        \n",
    "                        def generate_puzzle(diff):\n",
    "                            puzzle = generate_coding_puzzle(diff)\n",
    "                            desc = f\"**üéØ {diff} Challenge:** {puzzle['description']}\"\n",
    "                            return desc, puzzle['cpu_code'], \"\", puzzle\n",
    "                        \n",
    "                        def check_solution(user_code_input, puzzle):\n",
    "                            if not puzzle or not user_code_input:\n",
    "                                return \"Generate a puzzle and enter your solution!\"\n",
    "                            \n",
    "                            similarity = difflib.SequenceMatcher(None, \n",
    "                                                               user_code_input.strip(), \n",
    "                                                               puzzle['gpu_code'].strip()).ratio()\n",
    "                            \n",
    "                            if similarity > 0.8:\n",
    "                                user_state.points += 10\n",
    "                                return f\"üéâ Excellent! Perfect solution! +10 XP | Total: {user_state.points} XP\"\n",
    "                            elif similarity > 0.6:\n",
    "                                user_state.points += 5\n",
    "                                return f\"‚úÖ Good effort! Close solution. +5 XP | Total: {user_state.points} XP\\n\\nüí° **Hint:** Check your imports and variable names\"\n",
    "                            elif similarity > 0.4:\n",
    "                                user_state.points += 2\n",
    "                                return f\"üü° Partial credit for trying! +2 XP | Total: {user_state.points} XP\\n\\nüí° **Hints:**\\n‚Ä¢ Replace 'pandas' or 'pd' with 'cudf'\\n‚Ä¢ Check function names and syntax\\n‚Ä¢ Make sure to import cudf\"\n",
    "                            else:\n",
    "                                return f\"‚ùå Not quite right. No points awarded.\\n\\nüí° **Hints:**\\n‚Ä¢ Replace 'import pandas as pd' with 'import cudf'\\n‚Ä¢ Replace 'pd.DataFrame' with 'cudf.DataFrame'\\n‚Ä¢ Replace 'pd.' with 'cudf.' for other operations\\n\\n**Expected pattern:** {puzzle['gpu_code']}\"\n",
    "                        \n",
    "                        def run_benchmark(user_code_input, puzzle):\n",
    "                            if not puzzle:\n",
    "                                return \"Generate a puzzle first!\"\n",
    "                            \n",
    "                            similarity = difflib.SequenceMatcher(None, \n",
    "                                                               user_code_input.strip(), \n",
    "                                                               puzzle['gpu_code'].strip()).ratio()\n",
    "                            \n",
    "                            if similarity > 0.6:\n",
    "                                cpu_time = puzzle['cpu_time']\n",
    "                                gpu_time = puzzle['gpu_time']\n",
    "                                speedup = round(cpu_time / gpu_time, 1)\n",
    "                                return f\"‚ö° **Benchmark Results:**\\nüìä CPU: {cpu_time}s\\nüöÄ GPU: {gpu_time}s\\n‚ö° **Speedup: {speedup}x**\"\n",
    "                            else:\n",
    "                                return \"‚ùå Fix your solution first!\"\n",
    "                        \n",
    "                        gen_puzzle_btn.click(generate_puzzle, inputs=difficulty, \n",
    "                                           outputs=[puzzle_desc, cpu_code, user_code, puzzle_state])\n",
    "                        check_btn.click(check_solution, inputs=[user_code, puzzle_state], outputs=puzzle_feedback)\n",
    "                        benchmark_btn.click(run_benchmark, inputs=[user_code, puzzle_state], outputs=puzzle_feedback)\n",
    "                \n",
    "                # Update progress on point changes\n",
    "                def refresh_progress():\n",
    "                    return update_progress()\n",
    "                \n",
    "                # Connect progress updates\n",
    "                gen_quiz_btn.click(refresh_progress, outputs=progress)\n",
    "                check_btn.click(refresh_progress, outputs=progress)\n",
    "        \n",
    "        # Footer\n",
    "        gr.Markdown(\"\"\"\n",
    "        ---\n",
    "        <div style='text-align:center; color:#666; padding:15px;'>\n",
    "        üåü **AI Tutor Complete Learning System** ‚Ä¢ Structured Learning Paths ‚Ä¢ Socratic Guidance ‚Ä¢ Gamified Practice<br>\n",
    "        üìö <i>From beginner tutorials to advanced GPU computing - your complete data science learning companion!</i><br>\n",
    "        üí° **Learning Mode:** Topic-based structured courses | **Tutor Mode:** Socratic Q&A | **Game Mode:** XP-based practice\n",
    "        </div>\n",
    "        \"\"\")\n",
    "    \n",
    "    return app\n",
    "\n",
    "# === LAUNCH ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nüöÄ Creating AI Tutor interface...\")\n",
    "    app = create_ai_tutor()\n",
    "    \n",
    "    print(\"üéâ AI Tutor ready!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚úÖ Complete Learning System Available:\")\n",
    "    print(\"  üìö Learning Mode - Structured topic-based learning paths\")\n",
    "    print(\"  üéì Tutor Mode - Socratic Q&A with guided discovery\")\n",
    "    print(\"  üéÆ Game Mode - XP-based practice with flashcards, quizzes & coding\")\n",
    "    print(\"  üåü Dynamic content generation with contextual quotes\")\n",
    "    print(\"  üìñ Enhanced documentation (12+ sources)\")\n",
    "    print(\"  üéØ From beginner Python to advanced GPU computing\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Launch the app\n",
    "    app.launch(share=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431fcaf-1190-4ca1-a8c7-9f5d1fbf4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb36d5e3-f7d8-4871-9ce0-09edb7f556df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.12/site-packages (2.5.1+cu121)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.12/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (75.8.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.local/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.local/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.local/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m154.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m159.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/~~iton'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~cl'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~sparse'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~rand'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~fft'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~da_runtime'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~da_cupti'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~blas'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~dnn'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/~~rch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.26.2 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3ead1e-f418-4824-a033-b32a5de88a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchaudio==2.7.1\n",
      "  Downloading torchaudio-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torch==2.7.1 in ./.local/lib/python3.12/site-packages (from torchaudio==2.7.1) (2.7.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (75.8.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->torchaudio==2.7.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch==2.7.1->torchaudio==2.7.1) (3.0.2)\n",
      "Downloading torchaudio-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1+cu121\n",
      "    Uninstalling torchaudio-2.5.1+cu121:\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Successfully installed torchaudio-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchaudio==2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecd1892-18a5-4e19-b63b-4e34dc467b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.54.0.dev0', '2.7.1+cu126', '4.1.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import sentence_transformers\n",
    "transformers.__version__, torch.__version__, sentence_transformers.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d45e67f-26ee-4fc5-98af-735edd696bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: sentence-transformers 4.1.0\n",
      "Uninstalling sentence-transformers-4.1.0:\n",
      "  Successfully uninstalled sentence-transformers-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eef753a-de2e-46ef-a2a5-1673ba2c17dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.12/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.12/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d46f87-dabf-409c-9c8e-5e87d5cae602",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ~/.cache/huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f7e211-7db8-4fc8-8f08-21263e89e9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.53.0', '2.5.1+cu121', '4.1.0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import sentence_transformers\n",
    "transformers.__version__, torch.__version__, sentence_transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b7eef-4cd7-4a46-a063-d96dbf90148e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
