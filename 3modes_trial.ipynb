{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a3a683-92d3-41ed-be78-98dd6b89131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch>=2.6.0 faiss-cpu gradio>=4.19.2 numpy bs4 sentence-transformers transformers>=4.39.0 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17db6a5d-eb80-4240-ae19-8569b6886385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.12/site-packages (6.31.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbbc2d23-fcd8-48cc-8bae-a0f592ecc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfd187e-717d-40c8-9b72-e0306a7aea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in ./.local/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.local/lib/python3.12/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.local/lib/python3.12/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6ae57a-953e-4138-b398-11a031037e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: blobfile in ./.local/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in ./.local/lib/python3.12/site-packages (from blobfile) (3.23.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in ./.local/lib/python3.12/site-packages (from blobfile) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.9 in ./.local/lib/python3.12/site-packages (from blobfile) (6.0.0)\n",
      "Requirement already satisfied: filelock>=3.0 in ./.local/lib/python3.12/site-packages (from blobfile) (3.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install blobfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167e23cc-ed2c-45f9-ac2f-42e191917f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-nd0snhdj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-nd0snhdj\n",
      "  Resolved https://github.com/huggingface/transformers to commit ccf2ca162e33f381e454cdb74bf4b41a51ab976d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.12/site-packages (from transformers==4.54.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.54.0.dev0) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.54.0.dev0) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.54.0.dev0) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.12/site-packages (from requests->transformers==4.54.0.dev0) (2025.6.15)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.54.0.dev0-py3-none-any.whl size=11784316 sha256=513e41b12dfcab2f2bf18a56a161b82bb415cf2ce6a01a2300139e1d4fd4ead4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-grr3lrs9/wheels/49/a7/50/c9fdabbf10e51bb1256adb0c1a587fedd7184f5bad28d47fe3\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.53.0\n",
      "    Uninstalling transformers-4.53.0:\n",
      "      Successfully uninstalled transformers-4.53.0\n",
      "Successfully installed transformers-4.54.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28972d6f-1d90-4514-aa43-8a8b24734119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Loading microsoft/Phi-3-mini-4k-instruct on GPU (or device_map=auto)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a271b50c4ef4456c82a4ab837d04e19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b818ab6ad0c245acb99a7da293ede786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409a3b225bbf475493105126b736baf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb6f581b8f24da2b29156587d93831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a77f933e3143f7b9f6f3b629691c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7942b25133489e9e39ece7789f02f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890956d8478b479da7faa3108cb716f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc4eb2b73984eaa99b365e1534b9539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1127c0438ef244e48c8eeb3617786d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bed95f04e94cabae4a3fdb6c97a0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecc5a19beb8434598ba2d51484606af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a240e724ca548f1a8f5099790bccd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655a0ca5e2464bb68546004776e7b165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611d7d2b75cd4cfab4e0a6bcd673541c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM loaded and ready!\n",
      "\n",
      "🚀 Creating AI Tutor interface...\n",
      "🎉 AI Tutor ready!\n",
      "============================================================\n",
      "✅ Complete Learning System Available:\n",
      "  📚 Learning Mode - Structured topic-based learning paths\n",
      "  🎓 Tutor Mode - Socratic Q&A with guided discovery\n",
      "  🎮 Game Mode - XP-based practice with flashcards, quizzes & coding\n",
      "  🌟 Dynamic content generation with contextual quotes\n",
      "  📖 Enhanced documentation (12+ sources)\n",
      "  🎯 From beginner Python to advanced GPU computing\n",
      "============================================================\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://2978ed2dadfa7ea500.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2978ed2dadfa7ea500.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🚀 AI Tutor - Clean Working DataSci GPU Tutor (RAG + LLM + Game Mode)\n",
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "import torch\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import requests\n",
    "import random\n",
    "import difflib\n",
    "import re\n",
    "from types import SimpleNamespace\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, pipeline\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "# Includes: FAISS RAG system, fallback to Falcon-7B-Instruct, and full game mode\n",
    "\n",
    "\n",
    "# --- CONFIG ---\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "try:\n",
    "    embedder = SentenceTransformer(EMBED_MODEL, device='cuda')\n",
    "except (RuntimeError, OSError) as e:\n",
    "    print(f\"CUDA not available or out of memory ({e}), loading SentenceTransformer on CPU.\")\n",
    "    embedder = SentenceTransformer(EMBED_MODEL, device='cpu')\n",
    "#EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# LLM_MODEL = \"MiniMaxAI/SynLogic-7B\"\n",
    "# LLM_MODEL = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    " \n",
    "LLM_MODEL = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "#\"meta-llama/Meta-Llama-3-8B\"\n",
    "#\"allenai/digital-socrates-13b\"\n",
    "#\"/scratch/ntiwar12/huggingface/hub/models--WizardLM--WizardCoder-Python-34B-V1.0/snapshots/897fc6d9e12136c68c441b2350d015902c144b20/\"\n",
    "#\"allenai/digital-socrates-13b\"\n",
    "\n",
    "try:\n",
    "    print(f\"🤖 Loading {LLM_MODEL} on GPU (or device_map=auto)...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLM_MODEL,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    )\n",
    "except (RuntimeError, OSError) as e:\n",
    "    print(f\"⚠️ Failed to load on GPU: {e}\\nLoading {LLM_MODEL} on CPU...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLM_MODEL,\n",
    "        trust_remote_code=True,\n",
    "        device_map={\"\": \"cpu\"},\n",
    "        torch_dtype=torch.float32\n",
    "    )\n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    return_full_text=False,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(\"✅ LLM loaded and ready!\")\n",
    "#\"NousResearch/Hermes-2-Pro-Mistral-7B\"\n",
    "#https://huggingface.co/tecosys/Nutaan-RL1\n",
    "#https://huggingface.co/knowledgator/Qwen-encoder-0.5B\n",
    "#https://huggingface.co/knowledgator/Llama-encoder-1.0B\n",
    "CHUNK_FILE = \"chunks.pkl\"\n",
    "INDEX_FILE = \"faiss.index\" \n",
    "URLS_FILE = \"custom_urls.txt\"\n",
    "\n",
    "# Enhanced documentation system\n",
    "DOC_LINKS = {\n",
    "    'pandas': 'https://pandas.pydata.org/docs/',\n",
    "    'cudf': 'https://docs.rapids.ai/api/cudf/stable/',\n",
    "    'rapids': 'https://rapids.ai/',\n",
    "    'scikit-learn': 'https://scikit-learn.org/stable/',\n",
    "    'tensorflow': 'https://www.tensorflow.org/',\n",
    "    'pytorch': 'https://pytorch.org/docs/stable/',\n",
    "    'cuda_blog': 'https://developer.nvidia.com/blog/tag/cuda/',\n",
    "    'nvidia_tesla_whitepaper': 'https://www.nvidia.com/docs/io/116711/sc11-nv-tesla.pdf',\n",
    "    'gpu_compare': 'https://www.nvidia.com/en-us/geforce/graphics-cards/compare/',\n",
    "    'dsml_pdf': 'https://people.smp.uq.edu.au/DirkKroese/DSML/DSML.pdf',\n",
    "    'awesome_datascience': 'https://github.com/academic/awesome-datascience',\n",
    "    'gfg_ds_beginners': 'https://www.geeksforgeeks.org/data-science/data-science-for-beginners/'\n",
    "}\n",
    "\"\"\"\n",
    "# Initialize LLM pipeline (optional)\n",
    "llm_pipeline = None\n",
    "if TRANSFORMERS_AVAILABLE:\n",
    "    try:\n",
    "        print(\"🤖 Loading GPT-2 for dynamic content generation...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "        llm_pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            return_full_text=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        print(\"✅ LLM loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ LLM loading failed: {e}\")\n",
    "        llm_pipeline = None\n",
    "\"\"\"\n",
    "# === CORE FUNCTIONS ===\n",
    "\n",
    "def generate_contextual_quote(context=\"learning\", user_query=\"\"):\n",
    "    \"\"\"Generate contextual inspirational quotes\"\"\"\n",
    "    \n",
    "    # Try LLM generation first\n",
    "    if llm_pipeline:\n",
    "        try:\n",
    "            topic = extract_topic_from_query(user_query) if user_query else context\n",
    "            prompt = f\"Generate an inspiring quote about {topic} and learning:\"\n",
    "            result = llm_pipeline(prompt, max_new_tokens=50, temperature=0.8)\n",
    "            if result and len(result) > 0:\n",
    "                quote = result[0]['generated_text'].strip()\n",
    "                if len(quote) > 10:\n",
    "                    return f\"🧠 '{quote}' - AI Generated\"\n",
    "        except Exception as e:\n",
    "            print(f\"Quote generation error: {e}\")\n",
    "    \n",
    "    # Enhanced fallback quotes\n",
    "    quotes = [\n",
    "        \"💡 'Data is the new oil, but insights are the refined fuel.' - Anonymous\",\n",
    "        \"🚀 'The best way to get started is to quit talking and begin doing.' - Walt Disney\",\n",
    "        \"🧠 'Machine learning is the last invention that humanity will ever need to make.' - Nick Bostrom\",\n",
    "        \"⚡ 'GPU acceleration: Think parallel, compute faster!' - AI Generated\",\n",
    "        \"📊 'In data we trust, but insights we must discover!' - AI Generated\",\n",
    "        \"🔬 'Every algorithm learns from data, just like we learn from experience!' - AI Generated\",\n",
    "        \"🎯 'The goal is to turn data into information, and information into insight.' - Carly Fiorina\",\n",
    "        \"🌟 'Artificial intelligence is the new electricity.' - Andrew Ng\",\n",
    "        \"⚙️ 'The key to artificial intelligence has always been the representation.' - Jeff Hawkins\"\n",
    "    ]\n",
    "    return random.choice(quotes)\n",
    "\n",
    "def extract_topic_from_query(query):\n",
    "    \"\"\"Extract main topic from user query\"\"\"\n",
    "    if not query:\n",
    "        return \"learning\"\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    topic_keywords = {\n",
    "        'gpu computing': ['gpu', 'cuda', 'parallel', 'graphics'],\n",
    "        'data science': ['data', 'science', 'analytics', 'statistics'],\n",
    "        'machine learning': ['machine learning', 'ml', 'ai', 'artificial intelligence'],\n",
    "        'pandas': ['pandas', 'dataframe'],\n",
    "        'rapids': ['rapids', 'cudf', 'cuml'],\n",
    "        'programming': ['python', 'code', 'programming']\n",
    "    }\n",
    "    \n",
    "    for topic, keywords in topic_keywords.items():\n",
    "        if any(keyword in query_lower for keyword in keywords):\n",
    "            return topic\n",
    "    return 'learning'\n",
    "\n",
    "def smart_tutor_answer(query):\n",
    "    \"\"\"Generate Socratic tutor responses\"\"\"\n",
    "    if not query or query.strip() == \"\":\n",
    "        return \"🤔 Please ask me a question about data science, machine learning, or GPU computing!\", \"AI Tutor\"\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Topic-specific Socratic responses\n",
    "    if any(term in query_lower for term in ['rapids', 'cudf']):\n",
    "        return \"\"\"🤔 Let me guide you to discover RAPIDS:\n",
    "\n",
    "• What challenges do data scientists face with large datasets on CPUs?\n",
    "• How might GPU parallel processing help with data operations?\n",
    "• What would happen if pandas operations could run on thousands of cores?\n",
    "\n",
    "💡 **Hint:** RAPIDS bridges GPU computing with familiar data science APIs like pandas.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    elif 'cuda' in query_lower:\n",
    "        return \"\"\"🤔 Let's explore CUDA together:\n",
    "\n",
    "• What's the difference between CPU and GPU architecture?\n",
    "• Why might graphics cards be useful for non-graphics tasks?\n",
    "• How does parallel processing relate to data science?\n",
    "\n",
    "💡 **Hint:** CUDA stands for 'Compute Unified Device Architecture' - unified parallel computing.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    elif 'pandas' in query_lower:\n",
    "        return \"\"\"🤔 Let's think about pandas:\n",
    "\n",
    "• What real-world structure does a DataFrame resemble?\n",
    "• Why is structured data easier to work with than raw lists?\n",
    "• How do you think pandas got its name?\n",
    "\n",
    "💡 **Hint:** Think about spreadsheets, databases, and 'panel data' in statistics.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    elif any(term in query_lower for term in ['machine learning', 'ml']):\n",
    "        return \"\"\"🤔 Let's approach machine learning conceptually:\n",
    "\n",
    "• How is ML similar to how humans learn from experience?\n",
    "• What's the difference between writing rules vs. learning patterns?\n",
    "• Why might repetitive mathematical operations benefit from parallelization?\n",
    "\n",
    "💡 **Hint:** Consider the training process and computational intensity.\"\"\", \"Socratic Tutor\"\n",
    "    \n",
    "    # Generic response\n",
    "    return f\"\"\"🤔 Let's explore this together:\n",
    "\n",
    "• What do you already know about {query}?\n",
    "• How might this relate to data science or computing?\n",
    "• What would you want to accomplish by understanding this better?\n",
    "\n",
    "💡 **Hint:** Break down the concept into smaller parts and think about how each works.\"\"\", \"Socratic Tutor\"\n",
    "\n",
    "def generate_flashcards(topic, n=3):\n",
    "    \"\"\"Generate educational flashcards\"\"\"\n",
    "    \n",
    "    # Try LLM generation\n",
    "    if llm_pipeline:\n",
    "        try:\n",
    "            prompt = f\"Create {n} educational flashcards about {topic}. Format: Q: question A: answer\"\n",
    "            result = llm_pipeline(prompt, max_new_tokens=200, temperature=0.7)\n",
    "            if result:\n",
    "                # Parse the result into flashcards (simplified)\n",
    "                text = result[0]['generated_text']\n",
    "                # Basic parsing - in practice you'd want more robust parsing\n",
    "                if 'Q:' in text and 'A:' in text:\n",
    "                    # Create a simple flashcard from the generated text\n",
    "                    return [{\"front\": f\"Generated question about {topic}\", \"back\": f\"Generated answer about {topic}\"}]\n",
    "        except Exception as e:\n",
    "            print(f\"Flashcard generation error: {e}\")\n",
    "    \n",
    "    # Fallback flashcards\n",
    "    flashcard_pools = {\n",
    "        \"cudf\": [\n",
    "            {\"front\": \"What is cuDF?\", \"back\": \"cuDF is a GPU DataFrame library with pandas-like API.\"},\n",
    "            {\"front\": \"How to convert pandas to cuDF?\", \"back\": \"Use cudf.from_pandas(df)\"},\n",
    "            {\"front\": \"Main advantage of cuDF?\", \"back\": \"GPU acceleration for large dataset processing\"}\n",
    "        ],\n",
    "        \"pandas\": [\n",
    "            {\"front\": \"What is a DataFrame?\", \"back\": \"A 2D labeled data structure with columns of different types.\"},\n",
    "            {\"front\": \"How to read CSV in pandas?\", \"back\": \"pd.read_csv('filename.csv')\"},\n",
    "            {\"front\": \"How to select a column?\", \"back\": \"df['column_name'] or df.column_name\"}\n",
    "        ],\n",
    "        \"rapids\": [\n",
    "            {\"front\": \"What is RAPIDS?\", \"back\": \"A suite of GPU-accelerated data science libraries.\"},\n",
    "            {\"front\": \"Main RAPIDS libraries?\", \"back\": \"cuDF, cuML, cuGraph for DataFrames, ML, and graphs.\"},\n",
    "            {\"front\": \"RAPIDS vs traditional tools?\", \"back\": \"Same APIs but with GPU acceleration for massive speedups.\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Get cards for topic, with fallback\n",
    "    cards = flashcard_pools.get(topic.lower(), [\n",
    "        {\"front\": f\"What is {topic}?\", \"back\": f\"{topic} is an important concept in data science.\"},\n",
    "        {\"front\": f\"Why learn {topic}?\", \"back\": f\"Understanding {topic} improves your data science skills.\"}\n",
    "    ])\n",
    "    \n",
    "    return cards[:n]\n",
    "\n",
    "def generate_quiz(topic, n=2):\n",
    "    \"\"\"Generate quiz questions\"\"\"\n",
    "    \n",
    "    # Quiz pools by topic\n",
    "    quiz_pools = {\n",
    "        \"pandas\": [\n",
    "            {\"question\": \"What is the main data structure in pandas?\", \"options\": [\"DataFrame\", \"Array\", \"List\", \"Dict\"], \"answer_idx\": 0},\n",
    "            {\"question\": \"How do you read a CSV file?\", \"options\": [\"pd.read_csv()\", \"pd.load()\", \"pd.import()\", \"pd.open()\"], \"answer_idx\": 0}\n",
    "        ],\n",
    "        \"cudf\": [\n",
    "            {\"question\": \"cuDF accelerates which library?\", \"options\": [\"NumPy\", \"Pandas\", \"SciPy\", \"Matplotlib\"], \"answer_idx\": 1},\n",
    "            {\"question\": \"cuDF runs on which hardware?\", \"options\": [\"CPU\", \"GPU\", \"TPU\", \"FPGA\"], \"answer_idx\": 1}\n",
    "        ],\n",
    "        \"rapids\": [\n",
    "            {\"question\": \"RAPIDS is developed by?\", \"options\": [\"Google\", \"Facebook\", \"NVIDIA\", \"Microsoft\"], \"answer_idx\": 2},\n",
    "            {\"question\": \"Main RAPIDS component for DataFrames?\", \"options\": [\"cuML\", \"cuDF\", \"cuGraph\", \"cuPy\"], \"answer_idx\": 1}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    questions = quiz_pools.get(topic.lower(), [\n",
    "        {\"question\": f\"What is {topic}?\", \"options\": [\"A tool\", \"A library\", \"A concept\", \"All of above\"], \"answer_idx\": 3},\n",
    "        {\"question\": f\"Why is {topic} important?\", \"options\": [\"Performance\", \"Efficiency\", \"Scale\", \"All of above\"], \"answer_idx\": 3}\n",
    "    ])\n",
    "    \n",
    "    return random.sample(questions, min(n, len(questions)))\n",
    "\n",
    "def generate_coding_puzzle(difficulty=\"Beginner\"):\n",
    "    \"\"\"Generate coding puzzles for pandas to cuDF conversion\"\"\"\n",
    "    \n",
    "    puzzles = {\n",
    "        \"Beginner\": {\n",
    "            \"description\": \"Convert basic DataFrame creation from pandas to cuDF\",\n",
    "            \"cpu_code\": \"import pandas as pd\\ndf = pd.DataFrame({'a': [1, 2, 3]})\\nprint(df)\",\n",
    "            \"gpu_code\": \"import cudf\\ndf = cudf.DataFrame({'a': [1, 2, 3]})\\nprint(df)\",\n",
    "            \"cpu_time\": 1.2,\n",
    "            \"gpu_time\": 0.2\n",
    "        },\n",
    "        \"Intermediate\": {\n",
    "            \"description\": \"Convert groupby operation from pandas to cuDF\",\n",
    "            \"cpu_code\": \"import pandas as pd\\ndf = pd.DataFrame({'group': ['A', 'B', 'A'], 'value': [1, 2, 3]})\\nresult = df.groupby('group').sum()\",\n",
    "            \"gpu_code\": \"import cudf\\ndf = cudf.DataFrame({'group': ['A', 'B', 'A'], 'value': [1, 2, 3]})\\nresult = df.groupby('group').sum()\",\n",
    "            \"cpu_time\": 3.2,\n",
    "            \"gpu_time\": 0.5\n",
    "        },\n",
    "        \"Advanced\": {\n",
    "            \"description\": \"Convert complex aggregation from pandas to cuDF\",\n",
    "            \"cpu_code\": \"import pandas as pd\\ndf = pd.DataFrame({'cat': ['A', 'B'], 'val1': [1, 2], 'val2': [3, 4]})\\nresult = df.groupby('cat').agg({'val1': 'sum', 'val2': 'mean'})\",\n",
    "            \"gpu_code\": \"import cudf\\ndf = cudf.DataFrame({'cat': ['A', 'B'], 'val1': [1, 2], 'val2': [3, 4]})\\nresult = df.groupby('cat').agg({'val1': 'sum', 'val2': 'mean'})\",\n",
    "            \"cpu_time\": 4.2,\n",
    "            \"gpu_time\": 0.6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return puzzles.get(difficulty, puzzles[\"Beginner\"])\n",
    "\n",
    "def search_knowledge_base(query):\n",
    "    \"\"\"Enhanced RAG search with documentation\"\"\"\n",
    "    if not query:\n",
    "        return \"Please provide a specific question.\"\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Find relevant documentation\n",
    "    relevant_docs = []\n",
    "    for doc_name, doc_url in DOC_LINKS.items():\n",
    "        if any(term in doc_name for term in query_lower.split()):\n",
    "            relevant_docs.append(f\"• **{doc_name}**: {doc_url}\")\n",
    "    \n",
    "    if not relevant_docs:\n",
    "        # Default docs for common topics\n",
    "        if 'pandas' in query_lower:\n",
    "            relevant_docs = [f\"• **pandas**: {DOC_LINKS['pandas']}\"]\n",
    "        elif 'cudf' in query_lower:\n",
    "            relevant_docs = [f\"• **cudf**: {DOC_LINKS['cudf']}\"]\n",
    "        else:\n",
    "            relevant_docs = [f\"• **rapids**: {DOC_LINKS['rapids']}\"]\n",
    "    \n",
    "    context = f\"📚 **Relevant Documentation:**\\n\" + \"\\n\".join(relevant_docs[:3])\n",
    "    \n",
    "    # Add topic-specific information\n",
    "    if 'cudf' in query_lower:\n",
    "        context += \"\\n\\n💡 **Key Info:** cuDF provides pandas-like API with GPU acceleration\"\n",
    "    elif 'rapids' in query_lower:\n",
    "        context += \"\\n\\n💡 **Key Info:** RAPIDS ecosystem includes cuDF, cuML, cuGraph\"\n",
    "    elif 'pandas' in query_lower:\n",
    "        context += \"\\n\\n💡 **Key Info:** pandas provides DataFrames for data analysis\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# === GRADIO INTERFACE ===\n",
    "\n",
    "def create_ai_tutor():\n",
    "    \"\"\"Create the AI Tutor Gradio interface\"\"\"\n",
    "    \n",
    "    with gr.Blocks(theme=gr.themes.Soft(), title=\"🧠 AI Tutor\") as app:\n",
    "        \n",
    "        # Header\n",
    "        gr.Markdown(\"\"\"\n",
    "        <div style='text-align:center; background:linear-gradient(90deg,#fff1c1,#c1e7ff,#e1ffc1); border-radius:15px; padding:15px; margin-bottom:20px; color:#000;'>\n",
    "          <h1 style='color:#000; text-shadow: 1px 1px 2px rgba(0,0,0,0.1);'>🧠 AI Tutor - Complete Learning System</h1>\n",
    "          <h3 style='color:#000; font-weight:700; text-shadow: 1px 1px 2px rgba(0,0,0,0.1);'>📚 Learning Mode • 🎓 Socratic Tutoring • 🎮 Gamified Practice</h3>\n",
    "          <p style='color:#000; font-weight:600; text-shadow: 1px 1px 2px rgba(0,0,0,0.1);'><b>📚 Structured Learning Paths • 🤔 Guided Discovery • 🎯 Interactive Practice</b></p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Add custom CSS for better styling\n",
    "        app.css = \"\"\"\n",
    "        .learning-topic-btn {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;\n",
    "            color: white !important;\n",
    "            border: none !important;\n",
    "            border-radius: 12px !important;\n",
    "            padding: 15px !important;\n",
    "            margin: 8px !important;\n",
    "            font-weight: 600 !important;\n",
    "            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4) !important;\n",
    "            transition: all 0.3s ease !important;\n",
    "            min-height: 80px !important;\n",
    "            font-size: 14px !important;\n",
    "        }\n",
    "        .learning-topic-btn:hover {\n",
    "            transform: translateY(-2px) !important;\n",
    "            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6) !important;\n",
    "        }\n",
    "        \n",
    "        /* Make tab headers more prominent */\n",
    "        .gradio-tab-nav {\n",
    "            background: linear-gradient(90deg, #f8fafc, #e2e8f0) !important;\n",
    "            border-radius: 8px !important;\n",
    "            padding: 8px !important;\n",
    "            margin-bottom: 20px !important;\n",
    "            box-shadow: 0 2px 8px rgba(0,0,0,0.1) !important;\n",
    "        }\n",
    "        \n",
    "        .gradio-tab-nav .tab-nav {\n",
    "            background: linear-gradient(135deg, #4f46e5, #7c3aed) !important;\n",
    "            color: white !important;\n",
    "            font-weight: 700 !important;\n",
    "            font-size: 16px !important;\n",
    "            border-radius: 6px !important;\n",
    "            margin: 4px !important;\n",
    "            padding: 12px 20px !important;\n",
    "            box-shadow: 0 2px 4px rgba(79, 70, 229, 0.3) !important;\n",
    "            border: none !important;\n",
    "        }\n",
    "        \n",
    "        .gradio-tab-nav .tab-nav:hover {\n",
    "            background: linear-gradient(135deg, #6366f1, #8b5cf6) !important;\n",
    "            transform: translateY(-1px) !important;\n",
    "            box-shadow: 0 4px 8px rgba(79, 70, 229, 0.4) !important;\n",
    "        }\n",
    "        \n",
    "        .gradio-tab-nav .tab-nav.selected {\n",
    "            background: linear-gradient(135deg, #059669, #0d9488) !important;\n",
    "            box-shadow: 0 4px 12px rgba(5, 150, 105, 0.4) !important;\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        with gr.Tabs():\n",
    "            \n",
    "            # === LEARNING MODE ===\n",
    "            with gr.Tab(\"📚 Learning Mode\"):\n",
    "                gr.Markdown(\"### 🎯 **Choose a Learning Path - From Beginner to Advanced**\")\n",
    "                gr.Markdown(\"*Select any topic below to get a structured learning journey with resources and related topics*\")\n",
    "                \n",
    "                # Learning topics with structured paths\n",
    "                LEARNING_TOPICS = {\n",
    "                    \"Python for Data Science\": {\n",
    "                        \"description\": \"Master Python fundamentals and data science libraries\",\n",
    "                        \"level\": \"🟢 Beginner to Intermediate\",\n",
    "                        \"duration\": \"4-6 weeks\",\n",
    "                        \"prerequisites\": \"Basic programming knowledge\",\n",
    "                        \"content\": \"\"\"\n",
    "**📖 Learning Path:**\n",
    "1. **Python Basics** - Variables, data types, control structures\n",
    "2. **NumPy** - Numerical computing and arrays\n",
    "3. **Pandas** - Data manipulation and analysis\n",
    "4. **Matplotlib/Seaborn** - Data visualization\n",
    "5. **Jupyter Notebooks** - Interactive development\n",
    "\n",
    "**🔗 Key Resources:**\n",
    "• [Python.org Tutorial](https://docs.python.org/3/tutorial/)\n",
    "• [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "• [NumPy User Guide](https://numpy.org/doc/stable/user/)\n",
    "\n",
    "**🚀 Next Steps:** Machine Learning Fundamentals, Data Visualization\n",
    "\"\"\",\n",
    "                        \"related\": [\"Machine Learning Fundamentals\", \"Data Visualization\", \"Pandas Deep Dive\"]\n",
    "                    },\n",
    "                    \"Pandas Deep Dive\": {\n",
    "                        \"description\": \"Master DataFrame operations, data cleaning, and advanced pandas techniques\",\n",
    "                        \"level\": \"🟡 Intermediate\",\n",
    "                        \"duration\": \"3-4 weeks\", \n",
    "                        \"prerequisites\": \"Python basics, basic pandas knowledge\",\n",
    "                        \"content\": \"\"\"\n",
    "**📖 Learning Path:**\n",
    "1. **DataFrame Mastery** - Creation, indexing, selection\n",
    "2. **Data Cleaning** - Missing values, duplicates, data types\n",
    "3. **GroupBy Operations** - Aggregation and transformation\n",
    "4. **Merging & Joining** - Combining datasets\n",
    "5. **Performance Optimization** - Efficient pandas operations\n",
    "\n",
    "**🔗 Key Resources:**\n",
    "• [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "• [Pandas Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html)\n",
    "• [10 Minutes to Pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "\n",
    "**🚀 Next Steps:** GPU Acceleration with cuDF, Time Series Analysis\n",
    "\"\"\",\n",
    "                        \"related\": [\"GPU Acceleration with cuDF\", \"Data Visualization\", \"Time Series Analysis\"]\n",
    "                    },\n",
    "                    \"GPU Acceleration with cuDF\": {\n",
    "                        \"description\": \"Learn GPU-accelerated data processing with RAPIDS cuDF\",\n",
    "                        \"level\": \"🔴 Advanced\",\n",
    "                        \"duration\": \"2-3 weeks\",\n",
    "                        \"prerequisites\": \"Strong pandas knowledge, basic GPU concepts\",\n",
    "                        \"content\": \"\"\"\n",
    "**📖 Learning Path:**\n",
    "1. **GPU Computing Basics** - Understanding parallel processing\n",
    "2. **cuDF Introduction** - GPU DataFrames and basic operations\n",
    "3. **Migration from Pandas** - Converting existing code\n",
    "4. **Performance Optimization** - Memory management and best practices\n",
    "5. **Advanced Operations** - Complex aggregations and joins\n",
    "\n",
    "**🔗 Key Resources:**\n",
    "• [RAPIDS cuDF Documentation](https://docs.rapids.ai/api/cudf/stable/)\n",
    "• [cuDF User Guide](https://docs.rapids.ai/api/cudf/stable/user_guide/)\n",
    "• [RAPIDS Getting Started](https://rapids.ai/start.html)\n",
    "\n",
    "**🚀 Next Steps:** RAPIDS Ecosystem, Machine Learning with cuML\n",
    "\"\"\",\n",
    "                        \"related\": [\"RAPIDS Ecosystem\", \"CUDA Programming\", \"High-Performance Computing\"]\n",
    "                    },\n",
    "                    \"Machine Learning Fundamentals\": {\n",
    "                        \"description\": \"Core ML concepts, algorithms, and scikit-learn implementation\",\n",
    "                        \"level\": \"🟡 Intermediate\",\n",
    "                        \"duration\": \"6-8 weeks\",\n",
    "                        \"prerequisites\": \"Python, pandas, basic statistics\",\n",
    "                        \"content\": \"\"\"\n",
    "**📖 Learning Path:**\n",
    "1. **ML Concepts** - Supervised, unsupervised, reinforcement learning\n",
    "2. **Data Preprocessing** - Feature scaling, encoding, train-test splits\n",
    "3. **Regression Algorithms** - Linear, polynomial, regularization\n",
    "4. **Classification** - Logistic regression, decision trees, SVM\n",
    "5. **Model Evaluation** - Cross-validation, metrics, hyperparameter tuning\n",
    "\n",
    "**🔗 Key Resources:**\n",
    "• [Scikit-learn Documentation](https://scikit-learn.org/stable/)\n",
    "• [Machine Learning Course by Andrew Ng](https://www.coursera.org/learn/machine-learning)\n",
    "• [Hands-On Machine Learning](https://github.com/ageron/handson-ml2)\n",
    "\n",
    "**🚀 Next Steps:** Deep Learning, GPU-Accelerated ML with cuML\n",
    "\"\"\",\n",
    "                        \"related\": [\"Deep Learning Fundamentals\", \"GPU-Accelerated ML\", \"Data Science Projects\"]\n",
    "                    },\n",
    "                    \"RAPIDS Ecosystem\": {\n",
    "                        \"description\": \"Complete RAPIDS suite: cuDF, cuML, cuGraph for end-to-end GPU data science\",\n",
    "                        \"level\": \"🔴 Advanced\",\n",
    "                        \"duration\": \"4-5 weeks\",\n",
    "                        \"prerequisites\": \"GPU computing basics, pandas, scikit-learn\",\n",
    "                        \"content\": \"\"\"\n",
    "**📖 Learning Path:**\n",
    "1. **RAPIDS Overview** - cuDF, cuML, cuGraph, cuPy integration\n",
    "2. **cuDF Mastery** - Advanced DataFrame operations on GPU\n",
    "3. **cuML for ML** - GPU-accelerated machine learning algorithms\n",
    "4. **cuGraph** - Graph analytics and network analysis\n",
    "5. **End-to-End Workflows** - Complete GPU data science pipelines\n",
    "\n",
    "**🔗 Key Resources:**\n",
    "• [RAPIDS.ai Main Site](https://rapids.ai/)\n",
    "• [RAPIDS Documentation](https://docs.rapids.ai/)\n",
    "• [RAPIDS Community](https://github.com/rapidsai)\n",
    "\n",
    "**🚀 Next Steps:** Production Deployment, Multi-GPU Computing\n",
    "\"\"\",\n",
    "                        \"related\": [\"Multi-GPU Computing\", \"Production ML Systems\", \"CUDA Programming\"]\n",
    "                    },\n",
    "                    \"Data Visualization\": {\n",
    "                        \"description\": \"Create compelling data visualizations with matplotlib, seaborn, and plotly\",\n",
    "                        \"level\": \"🟢 Beginner to Intermediate\",\n",
    "                        \"duration\": \"3-4 weeks\",\n",
    "                        \"prerequisites\": \"Python basics, pandas fundamentals\",\n",
    "                        \"content\": \"\"\"\n",
    "**📖 Learning Path:**\n",
    "1. **Matplotlib Basics** - Plots, figures, axes, customization\n",
    "2. **Seaborn for Statistics** - Statistical plots and themes\n",
    "3. **Interactive Plotly** - Dynamic and web-ready visualizations\n",
    "4. **Advanced Techniques** - Subplots, animations, custom plots\n",
    "5. **Dashboard Creation** - Streamlit, Dash for interactive apps\n",
    "\n",
    "**🔗 Key Resources:**\n",
    "• [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)\n",
    "• [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html)\n",
    "• [Plotly Python Guide](https://plotly.com/python/)\n",
    "\n",
    "**🚀 Next Steps:** Interactive Dashboards, Business Intelligence\n",
    "\"\"\",\n",
    "                        \"related\": [\"Interactive Dashboards\", \"Business Intelligence\", \"Web Development for Data Science\"]\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                # Topic selection buttons\n",
    "                with gr.Row():\n",
    "                    topic_buttons = []\n",
    "                    for i, (topic_name, topic_info) in enumerate(LEARNING_TOPICS.items()):\n",
    "                        if i % 2 == 0 and i > 0:\n",
    "                            # Start new row every 2 buttons\n",
    "                            pass\n",
    "                        \n",
    "                        color_map = {\n",
    "                            \"🟢\": \"#dcfce7\",  # Green for beginner\n",
    "                            \"🟡\": \"#fef3c7\",  # Yellow for intermediate  \n",
    "                            \"🔴\": \"#fee2e2\"   # Red for advanced\n",
    "                        }\n",
    "                        level_color = color_map.get(topic_info[\"level\"][0], \"#f3f4f6\")\n",
    "                        \n",
    "                        btn = gr.Button(\n",
    "                            f\"{topic_name}\\n{topic_info['level']}\",\n",
    "                            elem_classes=\"learning-topic-btn\",\n",
    "                            size=\"lg\"\n",
    "                        )\n",
    "                        topic_buttons.append((btn, topic_name))\n",
    "                \n",
    "                # Learning content display\n",
    "                learning_content = gr.Markdown()\n",
    "                related_topics = gr.Markdown()\n",
    "                \n",
    "                def show_learning_content(topic_name):\n",
    "                    if topic_name not in LEARNING_TOPICS:\n",
    "                        return \"Topic not found!\", \"\"\n",
    "                    \n",
    "                    topic = LEARNING_TOPICS[topic_name]\n",
    "                    \n",
    "                    content = f\"\"\"\n",
    "# 📚 {topic_name}\n",
    "\n",
    "**📋 Description:** {topic['description']}\n",
    "\n",
    "**📊 Level:** {topic['level']} | **⏱️ Duration:** {topic['duration']} | **📚 Prerequisites:** {topic['prerequisites']}\n",
    "\n",
    "---\n",
    "\n",
    "{topic['content']}\n",
    "\n",
    "---\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    related = f\"\"\"\n",
    "### 🔗 **Related Learning Paths:**\n",
    "{' • '.join([f\"**{rel}**\" for rel in topic['related']])}\n",
    "\n",
    "💡 *Click any topic above to explore these related learning paths!*\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    return content, related\n",
    "                \n",
    "                # Connect buttons to content display\n",
    "                for btn, topic_name in topic_buttons:\n",
    "                    btn.click(\n",
    "                        lambda tn=topic_name: show_learning_content(tn),\n",
    "                        outputs=[learning_content, related_topics]\n",
    "                    )\n",
    "                \n",
    "                # Search functionality\n",
    "                with gr.Row():\n",
    "                    search_topic = gr.Textbox(\n",
    "                        label=\"🔍 Search for specific topics\",\n",
    "                        placeholder=\"e.g., neural networks, time series, NLP, computer vision...\"\n",
    "                    )\n",
    "                    search_btn = gr.Button(\"Search Learning Resources\")\n",
    "                \n",
    "                search_results = gr.Markdown()\n",
    "                \n",
    "                def search_learning_resources(query):\n",
    "                    if not query:\n",
    "                        return \"Please enter a search term!\"\n",
    "                    \n",
    "                    # Simulate search results with relevant resources\n",
    "                    query_lower = query.lower()\n",
    "                    \n",
    "                    results = []\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['neural', 'deep', 'cnn', 'rnn', 'transformer']):\n",
    "                        results.append(\"\"\"\n",
    "**🧠 Deep Learning Resources:**\n",
    "• [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)\n",
    "• [PyTorch Tutorials](https://pytorch.org/tutorials/)\n",
    "• [TensorFlow Guide](https://www.tensorflow.org/guide)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['nlp', 'text', 'language', 'sentiment']):\n",
    "                        results.append(\"\"\"\n",
    "**📝 Natural Language Processing:**\n",
    "• [NLTK Documentation](https://www.nltk.org/)\n",
    "• [spaCy Course](https://course.spacy.io/)\n",
    "• [Hugging Face Transformers](https://huggingface.co/transformers/)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['time series', 'forecasting', 'temporal']):\n",
    "                        results.append(\"\"\"\n",
    "**📈 Time Series Analysis:**\n",
    "• [Time Series Analysis Guide](https://www.statsmodels.org/stable/tsa.html)\n",
    "• [Prophet Forecasting](https://facebook.github.io/prophet/)\n",
    "• [Time Series with Python](https://github.com/marcopeix/TimeSeriesForecastingInPython)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if any(term in query_lower for term in ['computer vision', 'image', 'cv', 'opencv']):\n",
    "                        results.append(\"\"\"\n",
    "**👁️ Computer Vision:**\n",
    "• [OpenCV Tutorials](https://docs.opencv.org/master/d9/df8/tutorial_root.html)\n",
    "• [Computer Vision Course](https://www.coursera.org/learn/convolutional-neural-networks)\n",
    "• [Fast.ai Practical Deep Learning](https://course.fast.ai/)\n",
    "\"\"\")\n",
    "                    \n",
    "                    if not results:\n",
    "                        results.append(f\"\"\"\n",
    "**🔍 Search Results for \"{query}\":**\n",
    "\n",
    "*No specific resources found. Try these general resources:*\n",
    "• [Kaggle Learn](https://www.kaggle.com/learn) - Free micro-courses\n",
    "• [Coursera Data Science](https://www.coursera.org/browse/data-science)\n",
    "• [edX MIT Data Science](https://www.edx.org/course/introduction-to-computational-thinking-and-data-science)\n",
    "\n",
    "*Or refine your search with terms like: machine learning, deep learning, NLP, computer vision, time series*\n",
    "\"\"\")\n",
    "                    \n",
    "                    return \"\\n\".join(results)\n",
    "                \n",
    "                search_btn.click(search_learning_resources, inputs=search_topic, outputs=search_results)\n",
    "\n",
    "            # === TUTOR MODE ===\n",
    "            with gr.Tab(\"🎓 Tutor Mode\"):\n",
    "                gr.Markdown(\"### 🤔 **Socratic Learning - Ask Questions, Get Guided Answers**\")\n",
    "                gr.Markdown(\"*I won't give you direct answers, but I'll guide you to discover the knowledge yourself!*\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        tutor_query = gr.Textbox(\n",
    "                            label=\"Ask about Data Science, GPU Computing, or type 'docs' for documentation\",\n",
    "                            placeholder=\"e.g., What is RAPIDS? How does cuDF work? Why use GPU for data science?\",\n",
    "                            lines=2\n",
    "                        )\n",
    "                        tutor_btn = gr.Button(\"🚀 Get Socratic Guidance\", variant=\"primary\")\n",
    "                    \n",
    "                    with gr.Column(scale=1):\n",
    "                        quote_display = gr.Markdown(\"💡 *Ready to discover knowledge!*\")\n",
    "                \n",
    "                tutor_answer = gr.Markdown(label=\"🤔 Socratic Guidance\")\n",
    "                tutor_source = gr.Markdown(label=\"📚 Source\")\n",
    "                \n",
    "                # Quick question suggestions\n",
    "                with gr.Row():\n",
    "                    quick_questions = [\n",
    "                        \"Why use GPUs for data science?\",\n",
    "                        \"How does parallel processing work?\", \n",
    "                        \"What makes cuDF faster than pandas?\",\n",
    "                        \"When should I use machine learning?\"\n",
    "                    ]\n",
    "                    for i, question in enumerate(quick_questions):\n",
    "                        if i % 2 == 0:\n",
    "                            with gr.Column():\n",
    "                                pass\n",
    "                        quick_btn = gr.Button(f\"💭 {question}\", size=\"sm\")\n",
    "                        quick_btn.click(lambda q=question: q, outputs=tutor_query)\n",
    "                \n",
    "                def handle_tutor_query(query):\n",
    "                    if not query:\n",
    "                        return \"Please ask a question!\", \"AI Tutor\", \"💡 *Ready to help!*\"\n",
    "                    \n",
    "                    # Handle docs command\n",
    "                    if query.lower().strip() in ['docs', 'documentation', 'help']:\n",
    "                        docs_info = \"\"\"📚 **Available Documentation:**\n",
    "• **Core Libraries:** pandas, cuDF, RAPIDS, scikit-learn\n",
    "• **GPU Computing:** CUDA, NVIDIA resources  \n",
    "• **Data Science:** Comprehensive guides and tutorials\n",
    "*Ask any topic-specific question to get relevant documentation!*\"\"\"\n",
    "                        return docs_info, \"Documentation System\", \"📖 *Knowledge at your fingertips!*\"\n",
    "                    \n",
    "                    # Generate contextual quote\n",
    "                    quote = generate_contextual_quote(extract_topic_from_query(query), query)\n",
    "                    \n",
    "                    # Get tutor response\n",
    "                    answer, source = smart_tutor_answer(query)\n",
    "                    \n",
    "                    return answer, f\"**Source:** {source}\", f\"🌟 {quote}\"\n",
    "                \n",
    "                tutor_btn.click(handle_tutor_query, inputs=tutor_query, outputs=[tutor_answer, tutor_source, quote_display])\n",
    "                tutor_query.submit(handle_tutor_query, inputs=tutor_query, outputs=[tutor_answer, tutor_source, quote_display])\n",
    "            \n",
    "            # === GAME MODE ===\n",
    "            with gr.Tab(\"🎮 Game Mode\"):\n",
    "                user_state = SimpleNamespace(points=0)\n",
    "                \n",
    "                def update_progress():\n",
    "                    level = user_state.points // 20 + 1\n",
    "                    bar_width = min((user_state.points % 20) * 5, 100)\n",
    "                    return f\"\"\"<h3>🏆 Level {level} | 🔥 {user_state.points} XP</h3>\n",
    "                    <div style='background: #e5e7eb; height: 20px; border-radius: 10px;'>\n",
    "                        <div style='background: linear-gradient(90deg, #4ade80, #22c55e); height: 20px; width: {bar_width}%; border-radius: 10px;'></div>\n",
    "                    </div>\"\"\"\n",
    "                \n",
    "                progress = gr.HTML(update_progress())\n",
    "                \n",
    "                with gr.Tabs():\n",
    "                    \n",
    "                    # === FLASHCARDS ===\n",
    "                    with gr.Tab(\"🎴 Flashcards\"):\n",
    "                        flashcard_topic = gr.Textbox(label=\"Topic\", placeholder=\"e.g., cuDF, pandas, RAPIDS\")\n",
    "                        gen_flashcards_btn = gr.Button(\"✨ Generate Flashcards\")\n",
    "                        \n",
    "                        card_display = gr.Markdown()\n",
    "                        card_back = gr.Markdown(visible=False)\n",
    "                        flip_btn = gr.Button(\"🔄 Flip\", visible=False)\n",
    "                        next_btn = gr.Button(\"➡️ Next\", visible=False)\n",
    "                        \n",
    "                        flashcards_state = gr.State([])\n",
    "                        card_idx = gr.State(0)\n",
    "                        show_back = gr.State(False)\n",
    "                        \n",
    "                        def generate_cards(topic):\n",
    "                            if not topic:\n",
    "                                return \"Enter a topic first!\", \"\", gr.update(visible=False), gr.update(visible=False), [], 0, False\n",
    "                            \n",
    "                            cards = generate_flashcards(topic, 5)\n",
    "                            first_card = cards[0]\n",
    "                            return (\n",
    "                                f\"**Card 1/{len(cards)}**\\n\\n🎴 **Q:** {first_card['front']}\",\n",
    "                                \"\",\n",
    "                                gr.update(visible=True),\n",
    "                                gr.update(visible=True),\n",
    "                                cards,\n",
    "                                0,\n",
    "                                False\n",
    "                            )\n",
    "                        \n",
    "                        def flip_card(idx, show, cards):\n",
    "                            if not cards:\n",
    "                                return \"\", False\n",
    "                            card = cards[idx]\n",
    "                            if not show:\n",
    "                                return f\"**A:** {card['back']}\", True\n",
    "                            else:\n",
    "                                return \"\", False\n",
    "                        \n",
    "                        def next_card(idx, cards):\n",
    "                            if not cards:\n",
    "                                return \"\", 0, False\n",
    "                            new_idx = (idx + 1) % len(cards)\n",
    "                            card = cards[new_idx]\n",
    "                            user_state.points += 1\n",
    "                            return f\"**Card {new_idx+1}/{len(cards)}**\\n\\n🎴 **Q:** {card['front']}\", new_idx, False\n",
    "                        \n",
    "                        gen_flashcards_btn.click(generate_cards, inputs=flashcard_topic, \n",
    "                                               outputs=[card_display, card_back, flip_btn, next_btn, flashcards_state, card_idx, show_back])\n",
    "                        flip_btn.click(flip_card, inputs=[card_idx, show_back, flashcards_state], \n",
    "                                     outputs=[card_back, show_back])\n",
    "                        next_btn.click(next_card, inputs=[card_idx, flashcards_state], \n",
    "                                     outputs=[card_display, card_idx, show_back])\n",
    "                    \n",
    "                    # === QUIZ ===\n",
    "                    with gr.Tab(\"❓ Quiz\"):\n",
    "                        quiz_topic = gr.Textbox(label=\"Quiz Topic\", placeholder=\"e.g., pandas, cuDF, RAPIDS\")\n",
    "                        gen_quiz_btn = gr.Button(\"🧠 Generate Quiz\")\n",
    "                        \n",
    "                        quiz_q1 = gr.Markdown()\n",
    "                        quiz_r1 = gr.Radio(choices=[], label=\"Answer:\", visible=False)\n",
    "                        quiz_q2 = gr.Markdown()\n",
    "                        quiz_r2 = gr.Radio(choices=[], label=\"Answer:\", visible=False)\n",
    "                        \n",
    "                        submit_btn = gr.Button(\"Submit Quiz\", visible=False)\n",
    "                        quiz_result = gr.Markdown()\n",
    "                        quiz_state = gr.State([])\n",
    "                        \n",
    "                        def generate_quiz_questions(topic):\n",
    "                            if not topic:\n",
    "                                return \"Enter a topic!\", gr.update(visible=False), \"\", gr.update(visible=False), gr.update(visible=False), []\n",
    "                            \n",
    "                            questions = generate_quiz(topic, 2)\n",
    "                            return (\n",
    "                                f\"**Q1:** {questions[0]['question']}\",\n",
    "                                gr.update(choices=questions[0]['options'], visible=True, value=None),\n",
    "                                f\"**Q2:** {questions[1]['question']}\",\n",
    "                                gr.update(choices=questions[1]['options'], visible=True, value=None),\n",
    "                                gr.update(visible=True),\n",
    "                                questions\n",
    "                            )\n",
    "                        \n",
    "                        def evaluate_quiz(ans1, ans2, questions):\n",
    "                            if not questions:\n",
    "                                return \"Quiz not loaded!\"\n",
    "                            \n",
    "                            correct = 0\n",
    "                            result_parts = []\n",
    "                            \n",
    "                            # Check Q1\n",
    "                            correct_ans1 = questions[0]['options'][questions[0]['answer_idx']]\n",
    "                            if ans1 and ans1 == correct_ans1:\n",
    "                                correct += 1\n",
    "                                result_parts.append(f\"✅ **Q1:** Correct! ({ans1})\")\n",
    "                            else:\n",
    "                                result_parts.append(f\"❌ **Q1:** Wrong. You answered: {ans1 or 'None'}\")\n",
    "                                result_parts.append(f\"    💡 **Correct answer:** {correct_ans1}\")\n",
    "                            \n",
    "                            # Check Q2  \n",
    "                            correct_ans2 = questions[1]['options'][questions[1]['answer_idx']]\n",
    "                            if ans2 and ans2 == correct_ans2:\n",
    "                                correct += 1\n",
    "                                result_parts.append(f\"✅ **Q2:** Correct! ({ans2})\")\n",
    "                            else:\n",
    "                                result_parts.append(f\"❌ **Q2:** Wrong. You answered: {ans2 or 'None'}\")\n",
    "                                result_parts.append(f\"    💡 **Correct answer:** {correct_ans2}\")\n",
    "                            \n",
    "                            user_state.points += correct * 5\n",
    "                            \n",
    "                            # Overall result\n",
    "                            score_emoji = \"🎉\" if correct == 2 else \"👍\" if correct == 1 else \"📚\"\n",
    "                            result_parts.insert(0, f\"{score_emoji} **Final Score: {correct}/2 correct! +{correct*5} XP**\")\n",
    "                            result_parts.append(f\"\\n🏆 **Total XP:** {user_state.points}\")\n",
    "                            \n",
    "                            return \"\\n\".join(result_parts)\n",
    "                        \n",
    "                        gen_quiz_btn.click(generate_quiz_questions, inputs=quiz_topic,\n",
    "                                         outputs=[quiz_q1, quiz_r1, quiz_q2, quiz_r2, submit_btn, quiz_state])\n",
    "                        submit_btn.click(evaluate_quiz, inputs=[quiz_r1, quiz_r2, quiz_state], outputs=quiz_result)\n",
    "                    \n",
    "                    # === CODING PUZZLES ===\n",
    "                    with gr.Tab(\"💻 Coding\"):\n",
    "                        difficulty = gr.Radio(choices=[\"Beginner\", \"Intermediate\", \"Advanced\"], \n",
    "                                            value=\"Beginner\", label=\"Difficulty\")\n",
    "                        gen_puzzle_btn = gr.Button(\"🎯 Generate Puzzle\")\n",
    "                        \n",
    "                        puzzle_desc = gr.Markdown()\n",
    "                        cpu_code = gr.Code(label=\"CPU Code (pandas)\", interactive=False)\n",
    "                        user_code = gr.Code(label=\"Your GPU Code (cuDF)\", language=\"python\")\n",
    "                        \n",
    "                        check_btn = gr.Button(\"✅ Check Solution\")\n",
    "                        benchmark_btn = gr.Button(\"⚡ Benchmark\")\n",
    "                        \n",
    "                        puzzle_feedback = gr.Markdown()\n",
    "                        puzzle_state = gr.State({})\n",
    "                        \n",
    "                        def generate_puzzle(diff):\n",
    "                            puzzle = generate_coding_puzzle(diff)\n",
    "                            desc = f\"**🎯 {diff} Challenge:** {puzzle['description']}\"\n",
    "                            return desc, puzzle['cpu_code'], \"\", puzzle\n",
    "                        \n",
    "                        def check_solution(user_code_input, puzzle):\n",
    "                            if not puzzle or not user_code_input:\n",
    "                                return \"Generate a puzzle and enter your solution!\"\n",
    "                            \n",
    "                            similarity = difflib.SequenceMatcher(None, \n",
    "                                                               user_code_input.strip(), \n",
    "                                                               puzzle['gpu_code'].strip()).ratio()\n",
    "                            \n",
    "                            if similarity > 0.8:\n",
    "                                user_state.points += 10\n",
    "                                return f\"🎉 Excellent! Perfect solution! +10 XP | Total: {user_state.points} XP\"\n",
    "                            elif similarity > 0.6:\n",
    "                                user_state.points += 5\n",
    "                                return f\"✅ Good effort! Close solution. +5 XP | Total: {user_state.points} XP\\n\\n💡 **Hint:** Check your imports and variable names\"\n",
    "                            elif similarity > 0.4:\n",
    "                                user_state.points += 2\n",
    "                                return f\"🟡 Partial credit for trying! +2 XP | Total: {user_state.points} XP\\n\\n💡 **Hints:**\\n• Replace 'pandas' or 'pd' with 'cudf'\\n• Check function names and syntax\\n• Make sure to import cudf\"\n",
    "                            else:\n",
    "                                return f\"❌ Not quite right. No points awarded.\\n\\n💡 **Hints:**\\n• Replace 'import pandas as pd' with 'import cudf'\\n• Replace 'pd.DataFrame' with 'cudf.DataFrame'\\n• Replace 'pd.' with 'cudf.' for other operations\\n\\n**Expected pattern:** {puzzle['gpu_code']}\"\n",
    "                        \n",
    "                        def run_benchmark(user_code_input, puzzle):\n",
    "                            if not puzzle:\n",
    "                                return \"Generate a puzzle first!\"\n",
    "                            \n",
    "                            similarity = difflib.SequenceMatcher(None, \n",
    "                                                               user_code_input.strip(), \n",
    "                                                               puzzle['gpu_code'].strip()).ratio()\n",
    "                            \n",
    "                            if similarity > 0.6:\n",
    "                                cpu_time = puzzle['cpu_time']\n",
    "                                gpu_time = puzzle['gpu_time']\n",
    "                                speedup = round(cpu_time / gpu_time, 1)\n",
    "                                return f\"⚡ **Benchmark Results:**\\n📊 CPU: {cpu_time}s\\n🚀 GPU: {gpu_time}s\\n⚡ **Speedup: {speedup}x**\"\n",
    "                            else:\n",
    "                                return \"❌ Fix your solution first!\"\n",
    "                        \n",
    "                        gen_puzzle_btn.click(generate_puzzle, inputs=difficulty, \n",
    "                                           outputs=[puzzle_desc, cpu_code, user_code, puzzle_state])\n",
    "                        check_btn.click(check_solution, inputs=[user_code, puzzle_state], outputs=puzzle_feedback)\n",
    "                        benchmark_btn.click(run_benchmark, inputs=[user_code, puzzle_state], outputs=puzzle_feedback)\n",
    "                \n",
    "                # Update progress on point changes\n",
    "                def refresh_progress():\n",
    "                    return update_progress()\n",
    "                \n",
    "                # Connect progress updates\n",
    "                gen_quiz_btn.click(refresh_progress, outputs=progress)\n",
    "                check_btn.click(refresh_progress, outputs=progress)\n",
    "        \n",
    "        # Footer\n",
    "        gr.Markdown(\"\"\"\n",
    "        ---\n",
    "        <div style='text-align:center; color:#666; padding:15px;'>\n",
    "        🌟 **AI Tutor Complete Learning System** • Structured Learning Paths • Socratic Guidance • Gamified Practice<br>\n",
    "        📚 <i>From beginner tutorials to advanced GPU computing - your complete data science learning companion!</i><br>\n",
    "        💡 **Learning Mode:** Topic-based structured courses | **Tutor Mode:** Socratic Q&A | **Game Mode:** XP-based practice\n",
    "        </div>\n",
    "        \"\"\")\n",
    "    \n",
    "    return app\n",
    "\n",
    "# === LAUNCH ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n🚀 Creating AI Tutor interface...\")\n",
    "    app = create_ai_tutor()\n",
    "    \n",
    "    print(\"🎉 AI Tutor ready!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"✅ Complete Learning System Available:\")\n",
    "    print(\"  📚 Learning Mode - Structured topic-based learning paths\")\n",
    "    print(\"  🎓 Tutor Mode - Socratic Q&A with guided discovery\")\n",
    "    print(\"  🎮 Game Mode - XP-based practice with flashcards, quizzes & coding\")\n",
    "    print(\"  🌟 Dynamic content generation with contextual quotes\")\n",
    "    print(\"  📖 Enhanced documentation (12+ sources)\")\n",
    "    print(\"  🎯 From beginner Python to advanced GPU computing\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Launch the app\n",
    "    app.launch(share=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431fcaf-1190-4ca1-a8c7-9f5d1fbf4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb36d5e3-f7d8-4871-9ce0-09edb7f556df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.12/site-packages (2.5.1+cu121)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.12/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (75.8.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.local/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.local/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.local/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m154.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m159.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/~~iton'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~cl'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~sparse'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~rand'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~fft'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~da_runtime'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~da_cupti'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~blas'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/nvidia/~~dnn'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ntiwar12/.local/lib/python3.12/site-packages/~~rch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.26.2 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3ead1e-f418-4824-a033-b32a5de88a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchaudio==2.7.1\n",
      "  Downloading torchaudio-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torch==2.7.1 in ./.local/lib/python3.12/site-packages (from torchaudio==2.7.1) (2.7.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (75.8.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.local/lib/python3.12/site-packages (from torch==2.7.1->torchaudio==2.7.1) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->torchaudio==2.7.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch==2.7.1->torchaudio==2.7.1) (3.0.2)\n",
      "Downloading torchaudio-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1+cu121\n",
      "    Uninstalling torchaudio-2.5.1+cu121:\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Successfully installed torchaudio-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchaudio==2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecd1892-18a5-4e19-b63b-4e34dc467b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.54.0.dev0', '2.7.1+cu126', '4.1.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import sentence_transformers\n",
    "transformers.__version__, torch.__version__, sentence_transformers.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d45e67f-26ee-4fc5-98af-735edd696bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: sentence-transformers 4.1.0\n",
      "Uninstalling sentence-transformers-4.1.0:\n",
      "  Successfully uninstalled sentence-transformers-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eef753a-de2e-46ef-a2a5-1673ba2c17dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.12/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.12/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.local/lib/python3.12/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d46f87-dabf-409c-9c8e-5e87d5cae602",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ~/.cache/huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f7e211-7db8-4fc8-8f08-21263e89e9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.53.0', '2.5.1+cu121', '4.1.0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import sentence_transformers\n",
    "transformers.__version__, torch.__version__, sentence_transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b7eef-4cd7-4a46-a063-d96dbf90148e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
